"""
OKXå†å²Kçº¿æ•°æ®åŠ è½½å™¨

æ”¯æŒï¼š
1. ä»CSVæ–‡ä»¶åŠ è½½å†å²æ•°æ®
2. ä»OKX APIè·å–å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
3. æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import logging
from pathlib import Path
import json

logger = logging.getLogger(__name__)


class OKXDataLoader:
    """OKXå†å²Kçº¿æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, data_dir: str = "data/okx"):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
        """
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“‚ OKXæ•°æ®åŠ è½½å™¨åˆå§‹åŒ– | æ•°æ®ç›®å½•: {self.data_dir}")
    
    def load_from_csv(self, 
                      csv_path: str,
                      start_date: Optional[str] = None,
                      end_date: Optional[str] = None) -> pd.DataFrame:
        """
        ä»CSVæ–‡ä»¶åŠ è½½Kçº¿æ•°æ®
        
        CSVæ ¼å¼ï¼š
        timestamp,open,high,low,close,volume,turnover
        
        Args:
            csv_path: CSVæ–‡ä»¶è·¯å¾„
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œå¯é€‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œå¯é€‰
            
        Returns:
            DataFrame with columns: [timestamp, open, high, low, close, volume, turnover]
        """
        try:
            logger.info(f"ğŸ“¥ åŠ è½½CSVæ•°æ®: {csv_path}")
            
            # è¯»å–CSV
            df = pd.read_csv(csv_path)
            
            # éªŒè¯å¿…éœ€åˆ—
            required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise ValueError(f"CSVç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
            
            # è½¬æ¢æ—¶é—´æˆ³
            if df['timestamp'].dtype == 'object':
                df['timestamp'] = pd.to_datetime(df['timestamp'])
            elif df['timestamp'].dtype in ['int64', 'float64']:
                # å‡è®¾æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            # æ’åº
            df = df.sort_values('timestamp').reset_index(drop=True)
            
            # æ—¥æœŸè¿‡æ»¤
            if start_date:
                start = pd.to_datetime(start_date)
                df = df[df['timestamp'] >= start]
            
            if end_date:
                end = pd.to_datetime(end_date)
                df = df[df['timestamp'] <= end]
            
            logger.info(f"âœ… åŠ è½½æˆåŠŸ: {len(df)}æ¡Kçº¿æ•°æ®")
            logger.info(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
            logger.info(f"   ä»·æ ¼èŒƒå›´: ${df['close'].min():.2f} ~ ${df['close'].max():.2f}")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½CSVå¤±è´¥: {e}")
            raise
    
    def generate_sample_data(self,
                            symbol: str = "BTC/USDT",
                            days: int = 30,
                            interval: str = "1d",
                            start_price: float = 50000.0,
                            volatility: float = 0.02) -> pd.DataFrame:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿçš„Kçº¿æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        åŸºäºçœŸå®å¸‚åœºç‰¹å¾ï¼š
        - ä»·æ ¼éšæœºæ¸¸èµ°
        - æ³¢åŠ¨ç‡èšé›†
        - OHLCå…³ç³»æ­£ç¡®
        
        Args:
            symbol: äº¤æ˜“å¯¹
            days: å¤©æ•°
            interval: æ—¶é—´é—´éš”ï¼ˆ1d=æ—¥K, 1h=å°æ—¶Kï¼‰
            start_price: èµ·å§‹ä»·æ ¼
            volatility: æ³¢åŠ¨ç‡
            
        Returns:
            DataFrame with K-line data
        """
        logger.info(f"ğŸ² ç”Ÿæˆæ¨¡æ‹ŸKçº¿æ•°æ®: {symbol} | {days}å¤© | {interval}")
        
        # è®¡ç®—æ•°æ®ç‚¹æ•°é‡
        if interval == "1d":
            periods = days
            freq = "D"
        elif interval == "1h":
            periods = days * 24
            freq = "H"
        elif interval == "4h":
            periods = days * 6
            freq = "4H"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„interval: {interval}")
        
        # ç”Ÿæˆæ—¶é—´åºåˆ—
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        timestamps = pd.date_range(start=start_time, periods=periods, freq=freq)
        
        # ç”Ÿæˆä»·æ ¼åºåˆ—ï¼ˆéšæœºæ¸¸èµ° + æ³¢åŠ¨ç‡èšé›†ï¼‰
        np.random.seed(42)  # å¯å¤ç°
        
        prices = [start_price]
        current_vol = volatility
        
        for i in range(1, periods):
            # æ³¢åŠ¨ç‡èšé›†æ•ˆåº”
            vol_change = np.random.normal(0, 0.001)
            current_vol = np.clip(current_vol + vol_change, volatility * 0.5, volatility * 2.0)
            
            # ä»·æ ¼å˜åŒ–
            return_pct = np.random.normal(0, current_vol)
            new_price = prices[-1] * (1 + return_pct)
            
            # æ·»åŠ è¶‹åŠ¿ï¼ˆè½»å¾®ä¸Šæ¶¨åå¥½ï¼Œæ¨¡æ‹Ÿé•¿æœŸç‰›å¸‚ï¼‰
            trend = 0.0001
            new_price *= (1 + trend)
            
            prices.append(new_price)
        
        # ç”ŸæˆOHLCæ•°æ®
        data = []
        for i, (ts, close) in enumerate(zip(timestamps, prices)):
            # ç”Ÿæˆåˆç†çš„OHLC
            intraday_range = close * volatility * 0.5
            
            open_price = close + np.random.uniform(-intraday_range, intraday_range)
            high_price = max(open_price, close) + np.random.uniform(0, intraday_range)
            low_price = min(open_price, close) - np.random.uniform(0, intraday_range)
            
            # ç¡®ä¿OHLCå…³ç³»æ­£ç¡®
            high_price = max(high_price, open_price, close)
            low_price = min(low_price, open_price, close)
            
            # ç”Ÿæˆæˆäº¤é‡ï¼ˆä¸ä»·æ ¼æ³¢åŠ¨ç›¸å…³ï¼‰
            price_change = abs(close - open_price) / open_price
            base_volume = 1000000  # åŸºç¡€æˆäº¤é‡
            volume = base_volume * (1 + price_change * 10) * np.random.uniform(0.8, 1.2)
            
            data.append({
                'timestamp': ts,
                'open': open_price,
                'high': high_price,
                'low': low_price,
                'close': close,
                'volume': volume,
                'turnover': volume * close
            })
        
        df = pd.DataFrame(data)
        
        logger.info(f"âœ… ç”Ÿæˆå®Œæˆ: {len(df)}æ¡Kçº¿æ•°æ®")
        logger.info(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        logger.info(f"   ä»·æ ¼èŒƒå›´: ${df['close'].min():.2f} ~ ${df['close'].max():.2f}")
        logger.info(f"   æ”¶ç›Šç‡: {((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100:.2f}%")
        
        return df
    
    def save_to_csv(self, df: pd.DataFrame, filename: str):
        """
        ä¿å­˜æ•°æ®åˆ°CSV
        
        Args:
            df: DataFrame
            filename: æ–‡ä»¶å
        """
        filepath = self.data_dir / filename
        df.to_csv(filepath, index=False)
        logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {filepath}")
    
    def load_or_generate(self,
                        symbol: str = "BTC/USDT",
                        days: int = 30,
                        interval: str = "1d",
                        force_generate: bool = False) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆ
        
        Args:
            symbol: äº¤æ˜“å¯¹
            days: å¤©æ•°
            interval: æ—¶é—´é—´éš”
            force_generate: å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
            
        Returns:
            DataFrame
        """
        filename = f"{symbol.replace('/', '_')}_{interval}_{days}d.csv"
        filepath = self.data_dir / filename
        
        if filepath.exists() and not force_generate:
            logger.info(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½: {filename}")
            return self.load_from_csv(str(filepath))
        else:
            logger.info(f"ğŸ² ç”Ÿæˆæ–°æ•°æ®: {filename}")
            df = self.generate_sample_data(symbol, days, interval)
            self.save_to_csv(df, filename)
            return df
    
    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """
        éªŒè¯Kçº¿æ•°æ®è´¨é‡
        
        Args:
            df: DataFrame
            
        Returns:
            (is_valid, error_messages)
        """
        errors = []
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        missing = [col for col in required_cols if col not in df.columns]
        if missing:
            errors.append(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing}")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if df.isnull().any().any():
            null_cols = df.columns[df.isnull().any()].tolist()
            errors.append(f"å­˜åœ¨ç©ºå€¼: {null_cols}")
        
        # æ£€æŸ¥OHLCå…³ç³»
        invalid_ohlc = (
            (df['high'] < df['low']) |
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close'])
        )
        if invalid_ohlc.any():
            errors.append(f"OHLCå…³ç³»é”™è¯¯: {invalid_ohlc.sum()}æ¡")
        
        # æ£€æŸ¥ä»·æ ¼ä¸ºæ­£
        price_cols = ['open', 'high', 'low', 'close']
        for col in price_cols:
            if (df[col] <= 0).any():
                errors.append(f"{col}å­˜åœ¨éæ­£å€¼")
        
        # æ£€æŸ¥æ—¶é—´é¡ºåº
        if not df['timestamp'].is_monotonic_increasing:
            errors.append("æ—¶é—´æˆ³éå•è°ƒé€’å¢")
        
        is_valid = len(errors) == 0
        
        if is_valid:
            logger.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")
        else:
            logger.warning(f"âš ï¸ æ•°æ®éªŒè¯å¤±è´¥:\n  " + "\n  ".join(errors))
        
        return is_valid, errors
    
    def get_statistics(self, df: pd.DataFrame) -> Dict:
        """
        è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            df: DataFrame
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'data_points': len(df),
            'time_range': {
                'start': str(df['timestamp'].min()),
                'end': str(df['timestamp'].max()),
                'days': (df['timestamp'].max() - df['timestamp'].min()).days
            },
            'price': {
                'start': float(df['close'].iloc[0]),
                'end': float(df['close'].iloc[-1]),
                'min': float(df['close'].min()),
                'max': float(df['close'].max()),
                'mean': float(df['close'].mean()),
                'std': float(df['close'].std())
            },
            'returns': {
                'total': float((df['close'].iloc[-1] / df['close'].iloc[0] - 1) * 100),
                'daily_mean': float(df['close'].pct_change().mean() * 100),
                'daily_std': float(df['close'].pct_change().std() * 100)
            },
            'volume': {
                'total': float(df['volume'].sum()),
                'mean': float(df['volume'].mean()),
                'max': float(df['volume'].max())
            }
        }
        
        return stats


def test_okx_data_loader():
    """æµ‹è¯•OKXæ•°æ®åŠ è½½å™¨"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•OKXæ•°æ®åŠ è½½å™¨")
    print("="*60)
    
    loader = OKXDataLoader(data_dir="data/okx_test")
    
    # æµ‹è¯•1: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("\nğŸ“‹ æµ‹è¯•1: ç”Ÿæˆ30å¤©BTCæ—¥Kæ•°æ®")
    df = loader.generate_sample_data(
        symbol="BTC/USDT",
        days=30,
        interval="1d",
        start_price=50000.0,
        volatility=0.02
    )
    
    print(f"\nå‰5è¡Œæ•°æ®:")
    print(df.head())
    
    # æµ‹è¯•2: éªŒè¯æ•°æ®
    print("\nğŸ“‹ æµ‹è¯•2: éªŒè¯æ•°æ®è´¨é‡")
    is_valid, errors = loader.validate_data(df)
    print(f"éªŒè¯ç»“æœ: {'âœ… é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
    if errors:
        for error in errors:
            print(f"  - {error}")
    
    # æµ‹è¯•3: ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“‹ æµ‹è¯•3: ç»Ÿè®¡ä¿¡æ¯")
    stats = loader.get_statistics(df)
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # æµ‹è¯•4: ä¿å­˜å’ŒåŠ è½½
    print("\nğŸ“‹ æµ‹è¯•4: ä¿å­˜å’ŒåŠ è½½")
    loader.save_to_csv(df, "test_btc_30d.csv")
    
    df_loaded = loader.load_from_csv("data/okx_test/test_btc_30d.csv")
    print(f"åŠ è½½æ•°æ®: {len(df_loaded)}æ¡")
    print(f"æ•°æ®ä¸€è‡´æ€§: {'âœ… ä¸€è‡´' if len(df) == len(df_loaded) else 'âŒ ä¸ä¸€è‡´'}")
    
    # æµ‹è¯•5: åŠ è½½æˆ–ç”Ÿæˆï¼ˆç¼“å­˜æœºåˆ¶ï¼‰
    print("\nğŸ“‹ æµ‹è¯•5: ç¼“å­˜æœºåˆ¶")
    df_cached = loader.load_or_generate("BTC/USDT", days=30, force_generate=False)
    print(f"ä»ç¼“å­˜åŠ è½½: {len(df_cached)}æ¡")
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(message)s',
        datefmt='%H:%M:%S'
    )
    
    test_okx_data_loader()

