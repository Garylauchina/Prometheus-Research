"""
è¯„åˆ†æŒ‡æ ‡è®¡ç®—

5ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼š
1. RegimeConfidence - RegimeåŒ¹é…ç½®ä¿¡åº¦
2. StabilityScore - å¸‚åœºå¾®ç»“æ„ç¨³å®šæ€§
3. DangerIndex - ç»¼åˆé£é™©è¯„ä¼°
4. OpportunityIndex - äº¤æ˜“æœºä¼šè¯„ä¼°
5. NoveltyScore - æœªè§æƒ…å†µæ£€æµ‹
"""

from typing import List, Dict
import numpy as np
import logging

logger = logging.getLogger(__name__)


def calculate_regime_confidence(
    current_signature: 'WorldSignature_V2',
    regime_lib: 'RegimeLibrary'
) -> float:
    """
    è®¡ç®—RegimeåŒ¹é…ç½®ä¿¡åº¦
    
    Args:
        current_signature: å½“å‰ç­¾å
        regime_lib: Regimeåº“
    
    Returns:
        ç½®ä¿¡åº¦ [0, 1]
    """
    if regime_lib is None or len(regime_lib.regimes) == 0:
        return 0.0
    
    regime_id, similarity = regime_lib.match_regime(current_signature)
    
    return similarity


def calculate_stability_score(recent_micro_vecs: List[np.ndarray]) -> float:
    """
    è®¡ç®—å¸‚åœºå¾®ç»“æ„ç¨³å®šæ€§
    
    ç¨³å®šæ€§ = 1 - æ³¢åŠ¨ç‡ï¼ˆå½’ä¸€åŒ–ï¼‰
    
    Args:
        recent_micro_vecs: æœ€è¿‘çš„å¾®è§‚å‘é‡åˆ—è¡¨
    
    Returns:
        ç¨³å®šåº¦ [0, 1]ï¼Œè¶Šé«˜è¶Šç¨³å®š
    """
    if len(recent_micro_vecs) < 2:
        return 0.5  # é»˜è®¤ä¸­ç­‰ç¨³å®š
    
    # è®¡ç®—å‘é‡ä¹‹é—´çš„å˜åŒ–
    changes = []
    for i in range(1, len(recent_micro_vecs)):
        change = np.linalg.norm(recent_micro_vecs[i] - recent_micro_vecs[i-1])
        changes.append(change)
    
    if len(changes) == 0:
        return 0.5
    
    # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼‰
    mean_change = np.mean(changes)
    std_change = np.std(changes)
    
    if mean_change < 1e-6:
        return 1.0  # å®Œå…¨ç¨³å®š
    
    volatility = std_change / mean_change
    
    # è½¬æ¢ä¸ºç¨³å®šåº¦
    # volatilityä½ â†’ stabilityé«˜
    stability = 1 / (1 + volatility)
    
    return stability


def calculate_danger_index(micro_features: Dict[str, float]) -> float:
    """
    è®¡ç®—å±é™©æŒ‡æ•°
    
    ç»¼åˆè¯„ä¼°ï¼š
    - æ»‘ç‚¹ï¼ˆ30%æƒé‡ï¼‰
    - æ·±åº¦ä¸å¹³è¡¡ï¼ˆ30%æƒé‡ï¼‰
    - æµåŠ¨æ€§ï¼ˆ20%æƒé‡ï¼‰
    - æ³¢åŠ¨ç‡ï¼ˆ20%æƒé‡ï¼‰
    
    Args:
        micro_features: å¾®è§‚ç‰¹å¾
    
    Returns:
        å±é™©æŒ‡æ•° [0, 1]ï¼Œè¶Šé«˜è¶Šå±é™©
    """
    danger = 0.0
    
    # 1. æ»‘ç‚¹ï¼ˆæƒé‡0.3ï¼‰
    slippage = micro_features.get('slippage_estimate', 0.0005)
    # 0.1% â†’ 0åˆ†ï¼Œ1% â†’ æ»¡åˆ†
    slippage_score = min(slippage / 0.01, 1.0)
    danger += 0.3 * slippage_score
    
    # 2. æ·±åº¦ä¸å¹³è¡¡ï¼ˆæƒé‡0.3ï¼‰
    depth_imb = abs(micro_features.get('depth_imbalance', 0.0))
    # 0 â†’ 0åˆ†ï¼Œ0.5 â†’ æ»¡åˆ†
    imbalance_score = min(depth_imb / 0.5, 1.0)
    danger += 0.3 * imbalance_score
    
    # 3. æµåŠ¨æ€§ï¼ˆæƒé‡0.2ï¼‰
    total_liq = micro_features.get('total_liquidity', 200000)
    # æµåŠ¨æ€§ä½ â†’ å±é™©é«˜
    # 1000000 â†’ 0åˆ†ï¼Œ100000 â†’ æ»¡åˆ†
    if total_liq < 100000:
        liquidity_score = 1.0
    elif total_liq > 1000000:
        liquidity_score = 0.0
    else:
        liquidity_score = 1 - (total_liq - 100000) / 900000
    danger += 0.2 * liquidity_score
    
    # 4. å¾®è§‚æ³¢åŠ¨ç‡ï¼ˆæƒé‡0.2ï¼‰
    micro_vol = micro_features.get('micro_volatility', 0.001)
    # 0.1% â†’ 0åˆ†ï¼Œ0.5% â†’ æ»¡åˆ†
    vol_score = min(micro_vol / 0.005, 1.0)
    danger += 0.2 * vol_score
    
    return min(danger, 1.0)


def calculate_opportunity_index(
    macro_features: Dict[str, float],
    micro_features: Dict[str, float]
) -> float:
    """
    è®¡ç®—æœºä¼šæŒ‡æ•°
    
    ç»¼åˆè¯„ä¼°ï¼š
    - è¶‹åŠ¿å¼ºåº¦ï¼ˆ40%æƒé‡ï¼‰
    - æˆäº¤é‡ï¼ˆ30%æƒé‡ï¼‰
    - èµ„é‡‘è´¹ç‡å¥—åˆ©ï¼ˆ20%æƒé‡ï¼‰
    - æµåŠ¨æ€§ï¼ˆ10%æƒé‡ï¼‰
    
    Args:
        macro_features: å®è§‚ç‰¹å¾
        micro_features: å¾®è§‚ç‰¹å¾
    
    Returns:
        æœºä¼šæŒ‡æ•° [0, 1]ï¼Œè¶Šé«˜æœºä¼šè¶Šå¤§
    """
    opportunity = 0.0
    
    # 1. è¶‹åŠ¿å¼ºåº¦ï¼ˆæƒé‡0.4ï¼‰
    trend_slope = abs(macro_features.get('trend_slope', 0.0))
    # 0 â†’ 0åˆ†ï¼Œ5% â†’ æ»¡åˆ†
    trend_score = min(trend_slope / 0.05, 1.0)
    opportunity += 0.4 * trend_score
    
    # 2. æˆäº¤é‡æ¯”ç‡ï¼ˆæƒé‡0.3ï¼‰
    adv_ratio = macro_features.get('adv_ratio', 1.0)
    # 1.0 â†’ 0åˆ†ï¼Œ2.0ä»¥ä¸Š â†’ æ»¡åˆ†
    if adv_ratio > 2.0:
        volume_score = 1.0
    elif adv_ratio > 1.0:
        volume_score = (adv_ratio - 1.0) / 1.0
    else:
        volume_score = 0.0
    opportunity += 0.3 * volume_score
    
    # 3. èµ„é‡‘è´¹ç‡å¥—åˆ©æœºä¼šï¼ˆæƒé‡0.2ï¼‰
    funding = abs(macro_features.get('funding_rate', 0.0))
    # 0.05% â†’ 0åˆ†ï¼Œ0.1%ä»¥ä¸Š â†’ æ»¡åˆ†
    if funding > 0.001:
        funding_score = 1.0
    elif funding > 0.0005:
        funding_score = (funding - 0.0005) / 0.0005
    else:
        funding_score = 0.0
    opportunity += 0.2 * funding_score
    
    # 4. æµåŠ¨æ€§ï¼ˆæƒé‡0.1ï¼‰
    total_liq = micro_features.get('total_liquidity', 200000)
    # æµåŠ¨æ€§é«˜ â†’ æœºä¼šå¤§ï¼ˆå®¹æ˜“è¿›å‡ºï¼‰
    # 200000 â†’ 0åˆ†ï¼Œ1000000ä»¥ä¸Š â†’ æ»¡åˆ†
    if total_liq > 1000000:
        liquidity_score = 1.0
    elif total_liq > 200000:
        liquidity_score = (total_liq - 200000) / 800000
    else:
        liquidity_score = 0.0
    opportunity += 0.1 * liquidity_score
    
    return min(opportunity, 1.0)


def calculate_novelty_score(
    current_sig: 'WorldSignature_V2',
    historical_sigs: List['WorldSignature_V2'],
    window_size: int = 1000
) -> float:
    """
    è®¡ç®—æ–°é¢–åº¦
    
    NoveltyScore = 1 - max_similarity_to_history
    
    Args:
        current_sig: å½“å‰ç­¾å
        historical_sigs: å†å²ç­¾ååˆ—è¡¨
        window_size: æŸ¥æ‰¾çª—å£å¤§å°
    
    Returns:
        æ–°é¢–åº¦ [0, 1]ï¼Œè¶Šé«˜è¶Šæ–°é¢–
    """
    if len(historical_sigs) == 0:
        return 1.0  # å®Œå…¨æ–°é¢–ï¼ˆæ²¡æœ‰å†å²ï¼‰
    
    # å¯¼å…¥ç›¸ä¼¼åº¦è®¡ç®—å‡½æ•°
    from .signature import calculate_similarity
    
    # è®¡ç®—ä¸å†å²çš„æœ€å¤§ç›¸ä¼¼åº¦
    max_similarity = 0.0
    
    # åªçœ‹æœ€è¿‘window_sizeä¸ª
    recent_sigs = historical_sigs[-window_size:] if len(historical_sigs) > window_size else historical_sigs
    
    for hist_sig in recent_sigs:
        try:
            sim_result = calculate_similarity(current_sig, hist_sig)
            similarity = sim_result['overall']
            max_similarity = max(max_similarity, similarity)
        except Exception as e:
            logger.warning(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            continue
    
    # æ–°é¢–åº¦ = 1 - æœ€å¤§ç›¸ä¼¼åº¦
    novelty = 1 - max_similarity
    
    return novelty


def calculate_all_metrics(
    signature: 'WorldSignature_V2',
    regime_lib: 'RegimeLibrary' = None,
    recent_micro_vecs: List[np.ndarray] = None,
    historical_sigs: List['WorldSignature_V2'] = None
) -> Dict[str, float]:
    """
    ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
    
    Args:
        signature: å½“å‰ç­¾å
        regime_lib: Regimeåº“
        recent_micro_vecs: æœ€è¿‘çš„å¾®è§‚å‘é‡
        historical_sigs: å†å²ç­¾å
    
    Returns:
        æ‰€æœ‰æŒ‡æ ‡å­—å…¸
    """
    metrics = {}
    
    # 1. Regimeç½®ä¿¡åº¦
    if regime_lib:
        metrics['regime_confidence'] = calculate_regime_confidence(signature, regime_lib)
    else:
        metrics['regime_confidence'] = 0.0
    
    # 2. ç¨³å®šåº¦
    if recent_micro_vecs and len(recent_micro_vecs) > 1:
        metrics['stability_score'] = calculate_stability_score(recent_micro_vecs)
    else:
        metrics['stability_score'] = 0.5
    
    # 3. å±é™©æŒ‡æ•°
    metrics['danger_index'] = calculate_danger_index(signature.micro.raw_features)
    
    # 4. æœºä¼šæŒ‡æ•°
    metrics['opportunity_index'] = calculate_opportunity_index(
        signature.macro.raw_features,
        signature.micro.raw_features
    )
    
    # 5. æ–°é¢–åº¦
    if historical_sigs:
        metrics['novelty_score'] = calculate_novelty_score(signature, historical_sigs)
    else:
        metrics['novelty_score'] = 1.0
    
    return metrics


def interpret_metrics(metrics: Dict[str, float]) -> str:
    """
    è§£é‡ŠæŒ‡æ ‡å«ä¹‰
    
    Args:
        metrics: æŒ‡æ ‡å­—å…¸
    
    Returns:
        äººç±»å¯è¯»çš„è§£é‡Š
    """
    interpretation = []
    
    # Regimeç½®ä¿¡åº¦
    conf = metrics.get('regime_confidence', 0.0)
    if conf > 0.8:
        interpretation.append(f"âœ… é«˜ç½®ä¿¡åº¦åŒ¹é…åˆ°å·²çŸ¥regime ({conf:.1%})")
    elif conf > 0.5:
        interpretation.append(f"âš ï¸  ä¸­ç­‰ç½®ä¿¡åº¦åŒ¹é… ({conf:.1%})")
    else:
        interpretation.append(f"â“ ä½ç½®ä¿¡åº¦ï¼Œå¯èƒ½æ˜¯æ–°regime ({conf:.1%})")
    
    # ç¨³å®šåº¦
    stability = metrics.get('stability_score', 0.5)
    if stability > 0.8:
        interpretation.append(f"ğŸ“Š å¸‚åœºéå¸¸ç¨³å®š ({stability:.1%})")
    elif stability > 0.5:
        interpretation.append(f"ğŸ“Š å¸‚åœºä¸­ç­‰ç¨³å®š ({stability:.1%})")
    else:
        interpretation.append(f"âš¡ å¸‚åœºæ³¢åŠ¨å‰§çƒˆ ({stability:.1%})")
    
    # å±é™©æŒ‡æ•°
    danger = metrics.get('danger_index', 0.0)
    if danger > 0.7:
        interpretation.append(f"ğŸš¨ é«˜å±é™©ï¼å»ºè®®è°¨æ… ({danger:.1%})")
    elif danger > 0.4:
        interpretation.append(f"âš ï¸  ä¸­ç­‰é£é™© ({danger:.1%})")
    else:
        interpretation.append(f"âœ… ä½é£é™©ç¯å¢ƒ ({danger:.1%})")
    
    # æœºä¼šæŒ‡æ•°
    opportunity = metrics.get('opportunity_index', 0.5)
    if opportunity > 0.7:
        interpretation.append(f"ğŸ¯ é«˜æœºä¼šï¼å¯è€ƒè™‘å¢ä»“ ({opportunity:.1%})")
    elif opportunity > 0.4:
        interpretation.append(f"ğŸ’¡ ä¸­ç­‰æœºä¼š ({opportunity:.1%})")
    else:
        interpretation.append(f"ğŸ˜´ ä½æœºä¼šï¼Œå¯è§‚æœ› ({opportunity:.1%})")
    
    # æ–°é¢–åº¦
    novelty = metrics.get('novelty_score', 0.0)
    if novelty > 0.85:
        interpretation.append(f"ğŸ†• æåº¦æ–°é¢–ï¼æœªè§è¿‡çš„æƒ…å†µ ({novelty:.1%})")
    elif novelty > 0.6:
        interpretation.append(f"ğŸ†• è¾ƒæ–°æƒ…å†µ ({novelty:.1%})")
    else:
        interpretation.append(f"ğŸ“š å¸¸è§æƒ…å†µ ({novelty:.1%})")
    
    return "\n".join(interpretation)

