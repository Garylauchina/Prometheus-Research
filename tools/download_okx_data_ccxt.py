#!/usr/bin/env python3
"""
ğŸ“¥ OKXå†å²æ•°æ®ä¸‹è½½å·¥å…·ï¼ˆä½¿ç”¨CCXTåº“ï¼‰

ä½¿ç”¨ä¸“ä¸šçš„CCXTåº“è¿æ¥OKXï¼Œæ›´ç¨³å®šå¯é 
"""

import ccxt
import pandas as pd
import time
from datetime import datetime, timedelta
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


class OKXDataDownloaderCCXT:
    """OKXæ•°æ®ä¸‹è½½å™¨ï¼ˆä½¿ç”¨CCXTï¼‰"""
    
    def __init__(self, output_dir: str = "data/okx"):
        """åˆå§‹åŒ–"""
        self.exchange = ccxt.okx({'enableRateLimit': True})
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("ğŸ“¥ OKXæ•°æ®ä¸‹è½½å™¨åˆå§‹åŒ–ï¼ˆCCXTç‰ˆæœ¬ï¼‰")
        logger.info(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"   äº¤æ˜“æ‰€: {self.exchange.name}")
    
    def download_klines(self, symbol: str = "BTC/USDT", timeframe: str = "1d", days: int = 1000, max_requests: int = 50):
        """
        ä¸‹è½½Kçº¿æ•°æ®ï¼ˆå¾ªç¯ä¸‹è½½ï¼Œå°½å¯èƒ½å¤šï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹ï¼ˆBTC/USDTï¼‰
            timeframe: æ—¶é—´å‘¨æœŸï¼ˆ1m, 5m, 15m, 1h, 4h, 1dï¼‰
            days: ç›®æ ‡å¤©æ•°
            max_requests: æœ€å¤§è¯·æ±‚æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        """
        logger.info(f"\nğŸ“Š å¼€å§‹ä¸‹è½½ {symbol} {timeframe} Kçº¿æ•°æ®")
        logger.info(f"   ç›®æ ‡å¤©æ•°: {days}å¤©")
        logger.info(f"   æœ€å¤§è¯·æ±‚æ¬¡æ•°: {max_requests}æ¬¡")
        
        all_data = []
        
        # ä»å½“å‰æ—¶é—´å¼€å§‹å¾€å‰ä¸‹è½½
        since = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        limit = 100  # æ¯æ¬¡è¯·æ±‚100æ¡ï¼ˆOKXç¨³å®šæ”¯æŒï¼‰
        request_count = 0
        
        while request_count < max_requests:
            try:
                request_count += 1
                
                # è·å–æ•°æ®
                ohlcv = self.exchange.fetch_ohlcv(
                    symbol=symbol,
                    timeframe=timeframe,
                    since=since,
                    limit=limit
                )
                
                if not ohlcv:
                    logger.info(f"   ç¬¬{request_count}æ¬¡è¯·æ±‚: æ— æ•°æ®ï¼Œåœæ­¢")
                    break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æ•°æ®
                new_count = 0
                for candle in ohlcv:
                    if candle not in all_data:
                        all_data.append(candle)
                        new_count += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if request_count % 5 == 0 or new_count == 0:
                    logger.info(f"   è¯·æ±‚{request_count}: +{new_count}æ¡ï¼Œæ€»è®¡{len(all_data)}æ¡")
                
                # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œè¯´æ˜åˆ°å¤´äº†
                if new_count == 0:
                    logger.info(f"   âœ… å·²åˆ°è¾¾æœ€æ—©æ•°æ®ï¼ˆè¯·æ±‚{request_count}æ¬¡ï¼‰")
                    break
                
                # æ›´æ–°sinceä¸ºæœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´æˆ³+1
                since = ohlcv[-1][0] + 1
                
                # å¦‚æœè¿”å›çš„æ•°æ®å°‘äºlimitï¼Œå¯èƒ½æ¥è¿‘æœ€æ—©æ•°æ®
                if len(ohlcv) < limit:
                    logger.info(f"   âš ï¸ è¿”å›æ•°æ®<{limit}æ¡ï¼Œå¯èƒ½æ¥è¿‘æœ€æ—©æ•°æ®")
                    # ä½†ç»§ç»­å°è¯•
                
                # é¿å…è¯·æ±‚è¿‡å¿«ï¼ˆOKXé™åˆ¶ï¼š20æ¬¡/2ç§’ï¼‰
                time.sleep(0.15)
                
            except Exception as e:
                logger.error(f"âŒ ç¬¬{request_count}æ¬¡è¯·æ±‚å‡ºé”™: {e}")
                break
        
        if not all_data:
            logger.error("âŒ æœªè·å–åˆ°æ•°æ®")
            return None
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        # å»é‡å¹¶æ’åº
        df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
        
        logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {len(df)}æ¡Kçº¿")
        logger.info(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
        logger.info(f"   å®é™…å¤©æ•°: {(df['timestamp'].max() - df['timestamp'].min()).days}å¤©")
        
        return df
    
    def save_to_csv(self, df: pd.DataFrame, symbol: str, timeframe: str):
        """ä¿å­˜æ•°æ®"""
        if df is None or df.empty:
            logger.error("âŒ æ— æ•°æ®å¯ä¿å­˜")
            return None
        
        # ç”Ÿæˆæ–‡ä»¶å
        symbol_clean = symbol.replace('/', '_')
        filename = f"{symbol_clean}_{timeframe}_{datetime.now().strftime('%Y%m%d')}.csv"
        filepath = self.output_dir / filename
        
        # ä¿å­˜
        df.to_csv(filepath, index=False)
        
        file_size = filepath.stat().st_size / 1024
        logger.info(f"ğŸ’¾ å·²ä¿å­˜: {filepath}")
        logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
        logger.info(f"   æ•°æ®æ¡æ•°: {len(df)}æ¡")
        
        return filepath


def main():
    """ä¸»å‡½æ•°"""
    logger.info("\n" + "="*80)
    logger.info("ğŸ“¥ OKXå†å²æ•°æ®ä¸‹è½½å·¥å…·ï¼ˆCCXTç‰ˆæœ¬ï¼‰")
    logger.info("="*80)
    
    try:
        # åˆå§‹åŒ–
        downloader = OKXDataDownloaderCCXT(output_dir="data/okx")
        
        # ä¸‹è½½è®¡åˆ’ï¼ˆå°½å¯èƒ½å¤šçš„å†å²æ•°æ®ï¼‰
        plans = [
            {"timeframe": "1d", "days": 2000, "max_requests": 100, "desc": "æ—¥çº¿æ•°æ®ï¼ˆå°½å¯èƒ½å¤šï¼Œæœ€å¤š10000æ¡ï¼‰"},
            {"timeframe": "4h", "days": 730, "max_requests": 100, "desc": "4å°æ—¶çº¿ï¼ˆå°½å¯èƒ½å¤šï¼Œæœ€å¤š10000æ¡ï¼‰"},
            {"timeframe": "1h", "days": 365, "max_requests": 100, "desc": "1å°æ—¶çº¿ï¼ˆå°½å¯èƒ½å¤šï¼Œæœ€å¤š10000æ¡ï¼‰"},
        ]
        
        logger.info("\nğŸ“‹ ä¸‹è½½è®¡åˆ’:")
        for i, p in enumerate(plans, 1):
            logger.info(f"   {i}. {p['desc']}")
        
        results = []
        
        for i, plan in enumerate(plans, 1):
            logger.info(f"\n{'='*80}")
            logger.info(f"ğŸ“¥ ä»»åŠ¡ {i}/{len(plans)}: {plan['desc']}")
            logger.info(f"{'='*80}")
            
            try:
                df = downloader.download_klines(
                    symbol="BTC/USDT",
                    timeframe=plan['timeframe'],
                    days=plan['days'],
                    max_requests=plan.get('max_requests', 50)
                )
                
                if df is not None:
                    filepath = downloader.save_to_csv(df, "BTC/USDT", plan['timeframe'])
                    results.append({'timeframe': plan['timeframe'], 'success': True, 'filepath': filepath})
                else:
                    results.append({'timeframe': plan['timeframe'], 'success': False})
                
                if i < len(plans):
                    logger.info("\nâ¸ï¸  ä¼‘æ¯2ç§’...")
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {e}")
                results.append({'timeframe': plan['timeframe'], 'success': False, 'error': str(e)})
        
        # æ€»ç»“
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š ä¸‹è½½ä»»åŠ¡æ€»ç»“")
        logger.info("="*80)
        
        success_count = sum(1 for r in results if r['success'])
        logger.info(f"\nâœ… æˆåŠŸ: {success_count}/{len(results)}")
        
        for r in results:
            icon = "âœ…" if r['success'] else "âŒ"
            logger.info(f"\n{icon} {r['timeframe']}:")
            if r['success']:
                logger.info(f"   æ–‡ä»¶: {r['filepath']}")
            elif 'error' in r:
                logger.info(f"   é”™è¯¯: {r['error']}")
        
        logger.info("\n" + "="*80)
        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
        logger.info("="*80)
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

