"""
æ€§èƒ½æµ‹è¯•è„šæœ¬ - ç”¨äºæµ‹è¯•Prometheus v3.0çš„æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
"""

import os
import sys
import time
import logging
import argparse
import json
from datetime import datetime
import pandas as pd
import matplotlib.pyplot as plt

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

from live_trading_system import LiveTradingSystem
from config_virtual import CONFIG_VIRTUAL_TRADING

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f"performance_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("PerformanceTest")


def setup_performance_test_config():
    """
    è®¾ç½®æ€§èƒ½æµ‹è¯•çš„é…ç½®
    """
    config = CONFIG_VIRTUAL_TRADING.copy()
    
    # é…ç½®æ€§èƒ½æµ‹è¯•ä¸“ç”¨å‚æ•°
    config['performance_test'] = True
    config['performance_metrics_enabled'] = True
    config['max_agents'] = 20  # å¢åŠ ä»£ç†æ•°é‡ä»¥æµ‹è¯•å¹¶å‘æ€§èƒ½
    config['api_call_limit_per_minute'] = 300  # è®¾ç½®è¾ƒé«˜çš„APIè°ƒç”¨é™åˆ¶
    config['cache_ttl_seconds'] = 5  # è¾ƒçŸ­çš„ç¼“å­˜TTLä»¥æµ‹è¯•ç¼“å­˜åˆ·æ–°
    config['concurrent_agents_threshold'] = 10  # è¾ƒä½çš„å¹¶å‘é˜ˆå€¼ä»¥æ›´å®¹æ˜“è§¦å‘å¹¶å‘æ¨¡å¼
    
    # å‡å°‘æ¯ä¸ªå¾ªç¯çš„ä¼‘çœ æ—¶é—´ä»¥åŠ é€Ÿæµ‹è¯•
    config['trading_interval_seconds'] = 2
    
    return config


def run_performance_test(duration_seconds=300):
    """
    è¿è¡Œæ€§èƒ½æµ‹è¯•
    """
    logger.info("="*80)
    logger.info(f"å¼€å§‹æ€§èƒ½æµ‹è¯• - æŒç»­æ—¶é—´: {duration_seconds}ç§’")
    logger.info("="*80)
    
    # è®¾ç½®æµ‹è¯•é…ç½®
    config = setup_performance_test_config()
    okx_config = config['okx_api'].copy()
    okx_config['risk_config'] = config['risk']
    
    # éªŒè¯APIå‡­è¯
    if not all([okx_config['api_key'], okx_config['secret_key'], okx_config['passphrase']]):
        logger.error("åœ¨config_virtual.pyä¸­æœªæ‰¾åˆ°OKX APIå‡­è¯")
        return False
    
    try:
        # åˆ›å»ºäº¤æ˜“ç³»ç»Ÿ
        system = LiveTradingSystem(config, okx_config)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è¿è¡Œäº¤æ˜“ç³»ç»Ÿ
        system.run(duration_seconds=duration_seconds)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        actual_duration = end_time - start_time
        
        logger.info("="*80)
        logger.info(f"æ€§èƒ½æµ‹è¯•å®Œæˆ")
        logger.info(f"å®é™…è¿è¡Œæ—¶é—´: {actual_duration:.2f}ç§’")
        
        # æ”¶é›†æ€§èƒ½ç»Ÿè®¡æ•°æ®
        performance_stats = {
            'total_api_calls': system._total_api_calls,
            'throttled_api_calls': system._throttled_api_calls,
            'cache_hits': system._cache_hits,
            'cache_misses': system._cache_misses,
            'avg_agent_update_time': system._avg_agent_update_time,
            'avg_order_execution_time': system._avg_order_execution_time,
            'concurrent_updates': system._concurrent_updates_count,
            'serial_updates': system._serial_updates_count,
            'batch_trades_executed': system._batch_trades_executed,
            'total_trades': system._total_trades_executed
        }
        
        # æ‰“å°æ€§èƒ½ç»Ÿè®¡
        logger.info("\næ€§èƒ½ç»Ÿè®¡:")
        for key, value in performance_stats.items():
            logger.info(f"  {key}: {value}")
        
        # ä¿å­˜æ€§èƒ½æ•°æ®
        with open(f"performance_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
            json.dump(performance_stats, f, indent=2)
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        generate_performance_report(performance_stats, actual_duration)
        
        # éªŒè¯æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
        validate_performance_optimizations(performance_stats)
        
        return True
        
    except Exception as e:
        logger.error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


def generate_performance_report(performance_stats, duration):
    """
    ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    """
    try:
        # è®¡ç®—æ¯ç§’çš„APIè°ƒç”¨æ¬¡æ•°
        api_calls_per_second = performance_stats['total_api_calls'] / duration
        
        # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
        cache_hit_rate = (performance_stats['cache_hits'] / 
                         (performance_stats['cache_hits'] + performance_stats['cache_misses']) * 100) if \
                         (performance_stats['cache_hits'] + performance_stats['cache_misses']) > 0 else 0
        
        # è®¡ç®—å¹¶å‘ç‡
        total_updates = performance_stats['concurrent_updates'] + performance_stats['serial_updates']
        concurrent_rate = (performance_stats['concurrent_updates'] / total_updates * 100) if total_updates > 0 else 0
        
        logger.info("\næ€§èƒ½åˆ†ææŠ¥å‘Š:")
        logger.info(f"  APIè°ƒç”¨é¢‘ç‡: {api_calls_per_second:.2f} æ¬¡/ç§’")
        logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.2f}%")
        logger.info(f"  å¹¶å‘æ›´æ–°æ¯”ä¾‹: {concurrent_rate:.2f}%")
        logger.info(f"  å¹³å‡ä»£ç†æ›´æ–°æ—¶é—´: {performance_stats['avg_agent_update_time']:.4f} ç§’")
        logger.info(f"  å¹³å‡è®¢å•æ‰§è¡Œæ—¶é—´: {performance_stats['avg_order_execution_time']:.4f} ç§’")
        
        # å°è¯•ç”Ÿæˆå›¾è¡¨
        try:
            # åˆ›å»ºæ•°æ®æ¡†æ¶
            df = pd.DataFrame([performance_stats])
            
            # åˆ›å»ºå›¾è¡¨ç›®å½•
            os.makedirs('performance_charts', exist_ok=True)
            
            # ç»˜åˆ¶APIè°ƒç”¨ç»Ÿè®¡
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            # APIè°ƒç”¨ç»Ÿè®¡
            api_data = [
                performance_stats['total_api_calls'],
                performance_stats['throttled_api_calls']
            ]
            axes[0, 0].bar(['æ€»APIè°ƒç”¨', 'é™æµAPIè°ƒç”¨'], api_data)
            axes[0, 0].set_title('APIè°ƒç”¨ç»Ÿè®¡')
            axes[0, 0].set_ylabel('æ¬¡æ•°')
            
            # ç¼“å­˜ç»Ÿè®¡
            cache_data = [
                performance_stats['cache_hits'],
                performance_stats['cache_misses']
            ]
            axes[0, 1].pie(cache_data, labels=['ç¼“å­˜å‘½ä¸­', 'ç¼“å­˜æœªå‘½ä¸­'], autopct='%1.1f%%')
            axes[0, 1].set_title('ç¼“å­˜å‘½ä¸­ç‡')
            
            # æ›´æ–°æ¨¡å¼ç»Ÿè®¡
            update_data = [
                performance_stats['concurrent_updates'],
                performance_stats['serial_updates']
            ]
            axes[1, 0].pie(update_data, labels=['å¹¶å‘æ›´æ–°', 'ä¸²è¡Œæ›´æ–°'], autopct='%1.1f%%')
            axes[1, 0].set_title('ä»£ç†æ›´æ–°æ¨¡å¼åˆ†å¸ƒ')
            
            # äº¤æ˜“ç»Ÿè®¡
            trade_data = [
                performance_stats['batch_trades_executed'],
                performance_stats['total_trades']
            ]
            axes[1, 1].bar(['æ‰¹é‡äº¤æ˜“æ‰¹æ¬¡', 'æ€»äº¤æ˜“æ¬¡æ•°'], trade_data)
            axes[1, 1].set_title('äº¤æ˜“æ‰§è¡Œç»Ÿè®¡')
            axes[1, 1].set_ylabel('æ¬¡æ•°')
            
            plt.tight_layout()
            chart_file = f"performance_charts/performance_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(chart_file)
            logger.info(f"æ€§èƒ½å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_file}")
            
        except Exception as e:
            logger.warning(f"æ— æ³•ç”Ÿæˆæ€§èƒ½å›¾è¡¨: {e}")
            
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ—¶å‡ºé”™: {e}")


def validate_performance_optimizations(performance_stats):
    """
    éªŒè¯æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    logger.info("\næ€§èƒ½ä¼˜åŒ–åŠŸèƒ½éªŒè¯:")
    
    # æ£€æŸ¥APIè°ƒç”¨èŠ‚æµ
    if performance_stats['throttled_api_calls'] > 0:
        logger.info("âœ… APIè°ƒç”¨èŠ‚æµåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        logger.warning("âš ï¸  æœªæ£€æµ‹åˆ°APIè°ƒç”¨èŠ‚æµï¼Œå¯èƒ½éœ€è¦æ›´ä¸¥æ ¼çš„é™åˆ¶æˆ–æ›´é•¿çš„æµ‹è¯•æ—¶é—´")
    
    # æ£€æŸ¥ç¼“å­˜æœºåˆ¶
    if performance_stats['cache_hits'] > 0:
        logger.info("âœ… å¸‚åœºæ•°æ®ç¼“å­˜åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        logger.warning("âš ï¸  æœªæ£€æµ‹åˆ°ç¼“å­˜å‘½ä¸­ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç¼“å­˜é…ç½®æˆ–å¢åŠ é‡å¤è¯·æ±‚")
    
    # æ£€æŸ¥å¹¶å‘æ›´æ–°
    if performance_stats['concurrent_updates'] > 0:
        logger.info("âœ… å¹¶å‘ä»£ç†æ›´æ–°åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        logger.warning("âš ï¸  æœªæ£€æµ‹åˆ°å¹¶å‘ä»£ç†æ›´æ–°ï¼Œå¯èƒ½éœ€è¦å¢åŠ ä»£ç†æ•°é‡æˆ–è°ƒæ•´å¹¶å‘é˜ˆå€¼")
    
    # æ£€æŸ¥æ‰¹é‡äº¤æ˜“
    if performance_stats['batch_trades_executed'] > 0:
        logger.info("âœ… æ‰¹é‡äº¤æ˜“æ‰§è¡ŒåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        logger.warning("âš ï¸  æœªæ£€æµ‹åˆ°æ‰¹é‡äº¤æ˜“æ‰§è¡Œï¼Œå¯èƒ½éœ€è¦æ›´å¤šåŒæ—¶äº¤æ˜“ä¿¡å·")
    
    # æ€»ä½“è¯„ä¼°
    features_working = sum([
        1 if performance_stats['throttled_api_calls'] > 0 else 0,
        1 if performance_stats['cache_hits'] > 0 else 0,
        1 if performance_stats['concurrent_updates'] > 0 else 0,
        1 if performance_stats['batch_trades_executed'] > 0 else 0
    ])
    
    logger.info(f"\næ€§èƒ½ä¼˜åŒ–åŠŸèƒ½å·¥ä½œçŠ¶æ€: {features_working}/4")
    
    if features_working == 4:
        logger.info("ğŸ‰ æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½éªŒè¯é€šè¿‡!")
    else:
        logger.info("ğŸ“Š éƒ¨åˆ†æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½å·²éªŒè¯ï¼Œå»ºè®®è¿›ä¸€æ­¥è°ƒæ•´é…ç½®ä»¥æµ‹è¯•æ‰€æœ‰åŠŸèƒ½")


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='Prometheus v3.0 æ€§èƒ½æµ‹è¯•')
    parser.add_argument('--duration', type=int, default=300, help='æµ‹è¯•æŒç»­æ—¶é—´(ç§’)')
    parser.add_argument('--log-level', type=str, default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(getattr(logging, args.log_level))
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    success = run_performance_test(args.duration)
    
    if success:
        logger.info("\næ€§èƒ½æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        sys.exit(0)
    else:
        logger.error("\næ€§èƒ½æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == '__main__':
    main()
