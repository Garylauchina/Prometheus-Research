# Prometheus V13 — Development Plan (Draft) v0 — 2026-01-10

Status: **DRAFT** (intended to be frozen in small increments; do not over-design).

This document is a **development plan**, not a theory essay:
- What we will build
- What we will not build
- What evidence we must produce
- When we stop

V13 positioning (inherits One-Page SSOT):
- NOT_MEASURABLE is a **valid world output**, not an engineering failure.
- No proxies into adjudication (no synthetic world evidence).
- Do not adapt rules to “keep system usable”.

References:
- V13 One-Page SSOT: `docs/v13/V13_SSOT_STARTUP_ONE_PAGE_V0_20260110.md`
- V13 Capture Window minimal contract (very hard freeze; 3 textual facts files): `docs/v13/V13_SSOT_CAPTURE_WINDOW_MIN_CONTRACT_V0_20260110.md`
- V12 Survival Space SSOT (fail-closed, no L_liq fallback): `docs/v12/V12_SSOT_SURVIVAL_SPACE_EM_V1_20260108.md`
- V12 E-liquidity gate (coverage + hard ban on last_px-spread synthesis): `docs/v12/V12_GATE_E_LIQUIDITY_MEASURABILITY_V0_20260109.md`
- Provenance gate (expected_source=orderbook): `tools/v12/verify_orderbook_e_contract_provenance_gate_v0.py`

---

## 0) Executive summary (one paragraph)

V13 accepts that long-horizon replay adjudication may be impossible in this world. Therefore V13’s core workflow order is:

> **observe → name → constrain → systematize**

Engineering will try to pull us back to “design→implement→verify”. V13 must resist that by freezing a different pacing: code is first a sensor; adjudication is intentionally delayed.

---

## 0.1) The four-phase order (frozen pacing)

Phase 0 — Posture freeze (before code):
- success is not “it runs”
- NOT_MEASURABLE is a first-class output
- interface drift / world silence are phenomena, not bugs

Phase 1 — Observation-first (code as sensor):
- focus: WebSocket stability (not perfect), raw capture (append-only), per-window 3 textual facts files
- deliberately NOT doing: adjudication, computing L/gates, requiring 7-day continuity, requiring replay usability
- success condition: we can see at least one of:
  - world cooperates
  - world goes silent
  - world refuses
  - world changes behavior (drift)

Phase 2 — Phenomenon naming (not model-first):
- align multiple windows’ `phenomena.log.md`
- ask:
  - which phenomena repeat?
  - which are one-offs?
  - which co-occur / exclude each other?
- allow subjective naming; forbid mathification
- test: do multiple readers agree on the same phenomenon classes?

Phase 3 — Minimal constraints (only after phenomena exist):
- allow introducing gates/adjudication only as tools to test whether a phenomenon disappears/amplifies under a constraint

Phase 4 — Systematize & reproducibility (later, possibly V13 late / V14):
- only after we can say:
  - “phenomenon X disappears under Y, amplifies under Z”
- only then freeze directory norms, strengthen verifiers, pursue replay, cross-world claims

## 1) Goals (frozen intentions)

- **G1 — Build a real-time evidence pipeline** that can capture the world when it is willing to be observed:
  - order-book L1 (bid/ask) + trades (as provenance)
  - strict JSONL evidence, reconnect events, gaps, coverage stats

Execution translation (team internal, V13-specific):
- “We are testing whether the world is willing to be observed.”
  - In Phase 1, do not optimize for coverage thresholds.
  - In Phase 1, do not ask “can adjudication run?”
  - The only primary question: **what did the world do when we tried to observe?**

- **G2 — Build a replay dataset from captured evidence** (new era; do not mix with 2021–2022):
  - `market_snapshot.jsonl` includes real `bid_px_1/ask_px_1`
  - provenance manifest is auditable (no synthesis)
  - framing: dataset is an **archived observation attempt**, not a guaranteed reusable research object
    - avoid over-cleaning “for future reuse”
    - avoid aligning to old replay eras by introducing extra assumptions

- **G3 — Fail-closed gates are first a seismograph (recording tool), then a constitution**:
  - provenance gate (G0): orderbook source must be real
  - coverage gate (G1): bid/ask coverage must be quantified; PASS/NOT_MEASURABLE/FAIL semantics frozen
  - drift gate (G2): API schema/field drift is detected and recorded as “world drift”
  - interpretation rule (V13):
    - gate FAIL / NOT_MEASURABLE is not “this path is bad”
    - it is “the world refused / broke / drifted here”

- **G4 — Minimal adjudication demo** (probe only; de-emphasize / may be delayed):
  - run minimal `full` Survival Space runs against the new dataset and verify evidence chain
  - treat as “can adjudication be triggered at all in this window?”, not as a validation target
  - the outcome may be PASS, NOT_MEASURABLE, or drift; all are acceptable outputs

---

## 2) Non-goals (hard bans)

- **NG1**: Do not fabricate bid/ask from `last_px` or any fixed spread (synthetic order-book).
- **NG2**: Do not use trade-derived quotes as order-book restoration.
- **NG3**: Do not modify adjudication logic to accommodate missing evidence (“keep system usable”).
- **NG4**: Do not chase stable continuous world-pressure gauges as a success metric.
- **NG5**: Do not claim cross-era comparability (captured 2026 dataset is not 2021–2022 replay).

---

## 3) System boundary / repo boundary

- Research repo responsibility:
  - SSOT / pre-reg / acceptance gates
  - verifiers / summarizers
  - immutable archives of artifacts and blocker reports

- Quant repo responsibility:
  - real-time capture/recorder implementation
  - dataset builder from captured evidence
  - minimal runner execution under frozen contracts

Interaction rule:
- Any Quant-side work must be driven by **explicit delivery instruction files** in Research (absolute paths, do-or-die gates).

---

## 4) Workstreams (parallel, but freeze outputs before scaling)

### WS-A: Real-time capture (books5 + trades)

Deliverables:
- Recorder that writes:
  - `raw_books5.jsonl`
  - `raw_trades.jsonl`
  - `recorder_events.jsonl` (connect/disconnect, backoff, errors, throttling)
- Capture manifest:
  - endpoints, subscription params, sampling policy, gap policy, machine clock policy

Acceptance (Phase 1):
- Non-empty raw evidence exists OR silence/refusal is explicitly recorded.
- All gaps and reconnects are explicitly recorded (no silent loss).

Stop conditions:
- If API becomes unstable or schema drifts, record as drift output; do not “paper over”.

### WS-B: Dataset builder (live capture → replay dataset)

Deliverables:
- `dataset_replay_v2_live_orderbook_*` dataset_dir with:
  - `market_snapshot.jsonl` (1m ticks)
  - `dataset_build_manifest.json` with `orderbook_provenance` + coverage stats

Acceptance gates (Research-run):
- G0 provenance gate: PASS (expected_source=orderbook)
- G1 coverage gate: PASS (coverage >= 0.95, N>=1000)

### WS-C: Minimal adjudication demo (evidence integrity only)

Deliverables:
- Minimal `full` runs (3 seeds) on new dataset
- Research verifications PASS

Acceptance:
- `verify_survival_space_em_v1.py` PASS
- No forbidden fallback reason codes

Note (V13 pacing):
- WS-C should not pull schedule pressure from WS-A/WS-B. If capture is unstable, WS-C is intentionally postponed.

### WS-D: “World drift / silence registry” (V13-native reporting)

Deliverables:
- A small, append-only registry of:
  - drift events (schema change, endpoint behavior change, missing fields)
  - silence/refusal events (NOT_MEASURABLE gates)
  - their evidence pointers

Acceptance:
- Every blocker has a file under `docs/v13/artifacts/` with a minimal structured report.

Mandatory logging protocol (lightweight, no interpretation):
- See `docs/v13/V13_PHENOMENA_LOG_PROTOCOL_V0_20260110.md`
Hard freeze reminder:
- Per window, only the minimal textual artifacts are frozen; do not freeze directory depth or raw/binary requirements:
  - `docs/v13/V13_SSOT_CAPTURE_WINDOW_MIN_CONTRACT_V0_20260110.md`

---

## 5) Milestones (minimum viable, do-or-die)

### M0 — V13 documents bootstrap (this week)
- One-page SSOT exists (done)
- Dev plan v0 exists (this doc)
- Index entry exists

### M1 — Phase 1 “we can see” (T+1~3 days)
- We have multiple windows (not necessarily long) with the 3 textual files:
  - `window.meta.yaml` / `phenomena.log.md` / `verdict.md`
- We can point to at least one observable phenomenon:
  - cooperate / silence / refusal / drift

### M2 — Phase 2 naming alignment (T+4~10 days)
- We can align multiple windows and start a stable naming vocabulary.

### M3 — Phase 3 minimal constraints (T+10~21 days)
- Only after M2: introduce a minimal gate/adjudication probe to test whether a named phenomenon changes under a constraint.

Phase 4 is explicitly out of scope for “first 2–3 weeks”.

If any milestone fails due to world refusal/drift:
- record it; do not “fix” by proxying; decide whether to retry with a new capture window.

---

## 6) Acceptance artifacts checklist (what must exist on disk)

For any successful capture→dataset→run chain:
- `live_capture_root/` with raw JSONL + events JSONL
- `dataset_dir/market_snapshot.jsonl`
- `dataset_dir/dataset_build_manifest.json`
- Research gate reports:
  - provenance gate json
  - coverage gate json
- `runs_root/.../run_dir` (3 seeds)
- Research verifier reports for each run_dir
- A short README pointing to all of the above (immutable archive)

---

## 7) Immediate next action (what we do now)

Proceed with **Trial-12** as the sensor/capture track, but follow V13 pacing:
- In the next 7–10 days, only do:
  - continuous live capture (best-effort)
  - write the 3 window files
  - internal “what did we see?” discussion every 1–2 days
- Explicitly forbidden in the next 7–10 days:
  - “should we compute L now?”
  - “should we run adjudication now?”
  - “should we freeze directory norms now?”

