"""
Stage 1.1 è®­ç»ƒç»“æœæ·±åº¦åˆ†æ
===========================

åˆ†æå†…å®¹ï¼š
1. è¶…é«˜PFçš„çœŸå®åŸå› ï¼ˆtotal_profit vs total_lossï¼‰
2. ä¼˜ç§€åŸºå› çš„è¯¦ç»†ç‰¹å¾å’Œå…±æ€§
3. Agentè¡¨ç°ä¸ä½³çš„åŸå› 
4. Immigrationè§¦å‘æƒ…å†µ
5. åŸºå› æ”¶æ•›é€Ÿåº¦å’Œæ¼”åŒ–è¶‹åŠ¿
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import sqlite3
import json
import numpy as np
import pandas as pd
from collections import Counter


def analyze_super_genes():
    """åˆ†æ1ï¼šè¶…çº§åŸºå› ï¼ˆè¶…é«˜PFï¼‰çš„çœŸå®æƒ…å†µ"""
    print("\n" + "="*80)
    print("åˆ†æ1ï¼šè¶…çº§åŸºå› ï¼ˆPF > 1000ï¼‰æ·±åº¦å‰–æ")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æŸ¥è¯¢è¶…é«˜PFçš„è®°å½•
    cursor = conn.execute("""
        SELECT roi, profit_factor, trade_count, genome, run_id
        FROM best_genomes
        WHERE profit_factor > 1000
        ORDER BY profit_factor DESC
    """)
    
    records = cursor.fetchall()
    
    if not records:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°PF>1000çš„è®°å½•")
        conn.close()
        return
    
    print(f"æ‰¾åˆ° {len(records)} æ¡è¶…é«˜PFè®°å½•\n")
    
    # åˆ†æå‰3æ¡
    for i, (roi, pf, trade_count, genome_str, run_id) in enumerate(records[:3]):
        print(f"{'='*80}")
        print(f"è®°å½• #{i+1}")
        print(f"{'='*80}")
        
        genome = json.loads(genome_str)
        
        print(f"ROI: {roi*100:+.2f}%")
        print(f"Profit Factor: {pf:,.2f}")
        print(f"äº¤æ˜“æ•°: {trade_count}")
        print(f"Run ID: {run_id}")
        print(f"\nç­–ç•¥å‚æ•°:")
        for key, value in genome.items():
            print(f"  {key:25s}: {value:.4f}")
        
        # å°è¯•ä»run_idæ¨æ–­æ˜¯ç¬¬å‡ è½®ä¿å­˜
        if '_cycle' in run_id:
            cycle = run_id.split('_cycle')[-1]
            print(f"\nä¿å­˜å‘¨æœŸ: {cycle}")
        
        print("")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªAgent
    print(f"{'='*80}")
    print("é‡å¤æ€§æ£€æŸ¥")
    print(f"{'='*80}\n")
    
    genomes = [json.loads(row[3]) for row in records]
    unique_genomes = []
    
    for genome in genomes:
        is_duplicate = False
        for unique in unique_genomes:
            # æ£€æŸ¥æ˜¯å¦å®Œå…¨ç›¸åŒï¼ˆæ‰€æœ‰å‚æ•°éƒ½ä¸€æ ·ï¼‰
            if all(abs(genome.get(k, 0) - unique.get(k, 0)) < 1e-6 for k in genome.keys()):
                is_duplicate = True
                break
        if not is_duplicate:
            unique_genomes.append(genome)
    
    print(f"æ€»è®°å½•æ•°: {len(records)}")
    print(f"å”¯ä¸€åŸºå› æ•°: {len(unique_genomes)}")
    print(f"é‡å¤ç‡: {(len(records) - len(unique_genomes)) / len(records) * 100:.1f}%")
    
    if len(unique_genomes) < len(records):
        print(f"\nğŸ’¡ è¿™äº›è®°å½•æ˜¯åŒä¸€ä¸ªAgentåœ¨ä¸åŒå‘¨æœŸçš„å¿«ç…§")
        print(f"   æ¯50å‘¨æœŸä¿å­˜ä¸€æ¬¡ï¼Œæ‰€ä»¥åŒä¸€ä¸ªä¼˜ç§€Agentä¼šè¢«é‡å¤ä¿å­˜")
    
    conn.close()
    print("")


def analyze_excellent_genes():
    """åˆ†æ2ï¼šæ‰€æœ‰ä¼˜ç§€åŸºå› ï¼ˆPFâ‰¥2.0ï¼‰çš„å…±æ€§"""
    print("\n" + "="*80)
    print("åˆ†æ2ï¼šä¼˜ç§€åŸºå› ï¼ˆPFâ‰¥2.0ï¼‰å…±æ€§åˆ†æ")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    cursor = conn.execute("""
        SELECT roi, profit_factor, trade_count, genome
        FROM best_genomes
        WHERE profit_factor >= 2.0
        ORDER BY profit_factor DESC
    """)
    
    records = cursor.fetchall()
    
    if not records:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°PFâ‰¥2.0çš„è®°å½•")
        conn.close()
        return
    
    print(f"æ‰¾åˆ° {len(records)} æ¡ä¼˜ç§€åŸºå› è®°å½•\n")
    
    # æå–æ‰€æœ‰å‚æ•°
    params_list = []
    for roi, pf, trade_count, genome_str in records:
        genome = json.loads(genome_str)
        params_list.append(genome)
    
    # ç»Ÿè®¡æ¯ä¸ªå‚æ•°çš„åˆ†å¸ƒ
    param_stats = {}
    for key in params_list[0].keys():
        if key == 'generation':
            continue
        values = [p.get(key, 0) for p in params_list]
        param_stats[key] = {
            'mean': np.mean(values),
            'std': np.std(values),
            'min': np.min(values),
            'max': np.max(values)
        }
    
    print("å‚æ•°åˆ†å¸ƒ:")
    print(f"{'å‚æ•°':<30} {'å¹³å‡å€¼':>10} {'æ ‡å‡†å·®':>10} {'èŒƒå›´':>20}")
    print("-"*80)
    
    for key, stats in param_stats.items():
        print(f"{key:<30} {stats['mean']:>10.3f} {stats['std']:>10.3f} [{stats['min']:>6.3f}, {stats['max']:>6.3f}]")
    
    conn.close()
    print("")


def analyze_poor_performance():
    """åˆ†æ3ï¼šä¸ºä»€ä¹ˆ99.8%çš„åŸºå› è¡¨ç°ä¸ä½³ï¼Ÿ"""
    print("\n" + "="*80)
    print("åˆ†æ3ï¼šè¡¨ç°ä¸ä½³åŸºå› ï¼ˆPF<1.0ï¼‰åŸå› åˆ†æ")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # ç»Ÿè®¡ä¸åŒtrade_countåŒºé—´çš„PFåˆ†å¸ƒ
    cursor = conn.execute("""
        SELECT 
            CASE 
                WHEN trade_count = 0 THEN '0 (ä¸äº¤æ˜“)'
                WHEN trade_count <= 10 THEN '1-10'
                WHEN trade_count <= 50 THEN '11-50'
                WHEN trade_count <= 100 THEN '51-100'
                WHEN trade_count <= 500 THEN '101-500'
                ELSE '500+'
            END as trade_range,
            COUNT(*) as count,
            AVG(profit_factor) as avg_pf,
            AVG(roi) as avg_roi
        FROM best_genomes
        WHERE profit_factor < 1.0
        GROUP BY trade_range
        ORDER BY 
            CASE 
                WHEN trade_count = 0 THEN 0
                WHEN trade_count <= 10 THEN 1
                WHEN trade_count <= 50 THEN 2
                WHEN trade_count <= 100 THEN 3
                WHEN trade_count <= 500 THEN 4
                ELSE 5
            END
    """)
    
    print("æŒ‰äº¤æ˜“æ¬¡æ•°åˆ†ç»„:")
    print(f"{'äº¤æ˜“åŒºé—´':<15} {'æ•°é‡':>10} {'å¹³å‡PF':>12} {'å¹³å‡ROI':>12}")
    print("-"*80)
    
    for row in cursor:
        trade_range, count, avg_pf, avg_roi = row
        print(f"{trade_range:<15} {count:>10} {avg_pf:>12.2f} {avg_roi*100:>11.2f}%")
    
    print(f"\nğŸ’¡ åˆ†æ:")
    print(f"   - trade_count=0: Agentä»ä¸äº¤æ˜“ï¼ˆå¯èƒ½è¿‡äºä¿å®ˆï¼‰")
    print(f"   - trade_count>0ä½†PF<1.0: Agentäº¤æ˜“ä½†ç­–ç•¥ä¸ä½³ï¼ˆäºå¤šèµšå°‘ï¼‰")
    
    conn.close()
    print("")


def analyze_gene_evolution():
    """åˆ†æ4ï¼šåŸºå› æ¼”åŒ–è¶‹åŠ¿ï¼ˆé€šè¿‡run_idæ—¶é—´åºåˆ—ï¼‰"""
    print("\n" + "="*80)
    print("åˆ†æ4ï¼šåŸºå› æ¼”åŒ–è¶‹åŠ¿ï¼ˆæ”¶æ•›é€Ÿåº¦ï¼‰")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æŒ‰run_idï¼ˆåŒ…å«å‘¨æœŸä¿¡æ¯ï¼‰åˆ†ç»„ç»Ÿè®¡
    cursor = conn.execute("""
        SELECT 
            run_id,
            COUNT(*) as record_count,
            AVG(profit_factor) as avg_pf,
            MAX(profit_factor) as max_pf,
            AVG(roi) as avg_roi,
            MAX(roi) as max_roi
        FROM best_genomes
        GROUP BY run_id
        ORDER BY run_id
    """)
    
    records = list(cursor)
    
    print(f"æ€»å…± {len(records)} è½®ä¿å­˜\n")
    
    # åªæ˜¾ç¤ºå‰10è½®å’Œæœ€å10è½®
    print("ã€å‰10è½®ã€‘")
    print(f"{'è½®æ¬¡':<10} {'è®°å½•æ•°':>8} {'å¹³å‡PF':>12} {'æœ€é«˜PF':>15} {'å¹³å‡ROI':>12} {'æœ€é«˜ROI':>12}")
    print("-"*80)
    
    for i, (run_id, count, avg_pf, max_pf, avg_roi, max_roi) in enumerate(records[:10]):
        cycle = run_id.split('_cycle')[-1] if '_cycle' in run_id else '???'
        print(f"Cycle{cycle:<5} {count:>8} {avg_pf:>12.2f} {max_pf:>15.2f} {avg_roi*100:>11.2f}% {max_roi*100:>11.2f}%")
    
    print(f"\n{'... çœç•¥ä¸­é—´è½®æ¬¡ ...':^80}\n")
    
    print("ã€æœ€å10è½®ã€‘")
    print(f"{'è½®æ¬¡':<10} {'è®°å½•æ•°':>8} {'å¹³å‡PF':>12} {'æœ€é«˜PF':>15} {'å¹³å‡ROI':>12} {'æœ€é«˜ROI':>12}")
    print("-"*80)
    
    for i, (run_id, count, avg_pf, max_pf, avg_roi, max_roi) in enumerate(records[-10:]):
        cycle = run_id.split('_cycle')[-1] if '_cycle' in run_id else '???'
        print(f"Cycle{cycle:<5} {count:>8} {avg_pf:>12.2f} {max_pf:>15.2f} {avg_roi*100:>11.2f}% {max_roi*100:>11.2f}%")
    
    # åˆ†ææ”¶æ•›é€Ÿåº¦
    print(f"\n{'='*80}")
    print("æ”¶æ•›é€Ÿåº¦åˆ†æ")
    print(f"{'='*80}\n")
    
    # è®¡ç®—æ¯è½®çš„æœ€é«˜PF
    max_pfs = [row[3] for row in records]
    
    # æ‰¾åˆ°ç¬¬ä¸€æ¬¡å‡ºç°PF>2.0çš„è½®æ¬¡
    first_excellent = None
    for i, (run_id, count, avg_pf, max_pf, avg_roi, max_roi) in enumerate(records):
        if max_pf >= 2.0:
            first_excellent = i
            break
    
    if first_excellent is not None:
        cycle = records[first_excellent][0].split('_cycle')[-1] if '_cycle' in records[first_excellent][0] else '???'
        print(f"âœ… ç¬¬ä¸€æ¬¡å‡ºç°ä¼˜ç§€åŸºå› ï¼ˆPFâ‰¥2.0ï¼‰: ç¬¬{first_excellent+1}è½®ï¼ˆCycle {cycle}ï¼‰")
        print(f"   æ”¶æ•›é€Ÿåº¦: {int(cycle) if cycle.isdigit() else '???'} å‘¨æœŸ")
    else:
        print(f"âš ï¸ æ•´ä¸ªè®­ç»ƒæœŸé—´æ²¡æœ‰å‡ºç°PFâ‰¥2.0çš„åŸºå› ")
    
    conn.close()
    print("")


def analyze_directional_bias_impact():
    """åˆ†æ5ï¼šdirectional_biaså¯¹è¡¨ç°çš„å½±å“"""
    print("\n" + "="*80)
    print("åˆ†æ5ï¼šæ–¹å‘åå¥½ï¼ˆdirectional_biasï¼‰å¯¹è¡¨ç°çš„å½±å“")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    cursor = conn.execute("""
        SELECT roi, profit_factor, trade_count, genome
        FROM best_genomes
    """)
    
    # æŒ‰directional_biasåˆ†ç»„ç»Ÿè®¡
    bins = {
        'å¼ºç©º(<0.2)': [],
        'åç©º(0.2-0.4)': [],
        'ä¸­æ€§(0.4-0.6)': [],
        'åå¤š(0.6-0.8)': [],
        'å¼ºå¤š(>0.8)': []
    }
    
    for roi, pf, trade_count, genome_str in cursor:
        genome = json.loads(genome_str)
        bias = genome.get('directional_bias', 0.5)
        
        if bias < 0.2:
            bins['å¼ºç©º(<0.2)'].append((roi, pf, trade_count))
        elif bias < 0.4:
            bins['åç©º(0.2-0.4)'].append((roi, pf, trade_count))
        elif bias < 0.6:
            bins['ä¸­æ€§(0.4-0.6)'].append((roi, pf, trade_count))
        elif bias < 0.8:
            bins['åå¤š(0.6-0.8)'].append((roi, pf, trade_count))
        else:
            bins['å¼ºå¤š(>0.8)'].append((roi, pf, trade_count))
    
    print(f"{'æ–¹å‘åå¥½':<15} {'æ•°é‡':>8} {'å¹³å‡ROI':>12} {'å¹³å‡PF':>12} {'å¹³å‡äº¤æ˜“':>10}")
    print("-"*80)
    
    for bin_name, records in bins.items():
        if not records:
            continue
        
        count = len(records)
        avg_roi = np.mean([r[0] for r in records])
        avg_pf = np.mean([r[1] for r in records])
        avg_trades = np.mean([r[2] for r in records])
        
        print(f"{bin_name:<15} {count:>8} {avg_roi*100:>11.2f}% {avg_pf:>12.2f} {avg_trades:>10.1f}")
    
    print(f"\nğŸ’¡ åˆ†æ:")
    print(f"   - å¸‚åœºåŒ…å«trend_upå’Œtrend_downï¼Œç†è®ºä¸Šå¤šç©ºç­–ç•¥éƒ½åº”è¯¥èƒ½ç›ˆåˆ©")
    print(f"   - å¦‚æœæŸä¸ªæ–¹å‘æ˜æ˜¾ä¼˜äºå…¶ä»–ï¼Œè¯´æ˜å¸‚åœºç»“æ„ä¸å¹³è¡¡æˆ–ç­–ç•¥æœ‰å")
    
    conn.close()
    print("")


def analyze_trade_activity():
    """åˆ†æ6ï¼šäº¤æ˜“æ´»è·ƒåº¦åˆ†æ"""
    print("\n" + "="*80)
    print("åˆ†æ6ï¼šäº¤æ˜“æ´»è·ƒåº¦åˆ†æ")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    cursor = conn.execute("""
        SELECT trade_count FROM best_genomes
    """)
    
    trade_counts = [row[0] for row in cursor]
    
    zero_trades = sum(1 for t in trade_counts if t == 0)
    low_trades = sum(1 for t in trade_counts if 0 < t <= 10)
    medium_trades = sum(1 for t in trade_counts if 10 < t <= 100)
    high_trades = sum(1 for t in trade_counts if 100 < t <= 1000)
    very_high_trades = sum(1 for t in trade_counts if t > 1000)
    
    total = len(trade_counts)
    
    print(f"äº¤æ˜“æ´»è·ƒåº¦åˆ†å¸ƒ:")
    print(f"{'ç±»åˆ«':<20} {'æ•°é‡':>10} {'å æ¯”':>10}")
    print("-"*80)
    print(f"{'ä¸äº¤æ˜“(0)':<20} {zero_trades:>10} {zero_trades/total*100:>9.1f}%")
    print(f"{'ä½é¢‘(1-10)':<20} {low_trades:>10} {low_trades/total*100:>9.1f}%")
    print(f"{'ä¸­é¢‘(11-100)':<20} {medium_trades:>10} {medium_trades/total*100:>9.1f}%")
    print(f"{'é«˜é¢‘(101-1000)':<20} {high_trades:>10} {high_trades/total*100:>9.1f}%")
    print(f"{'æé«˜é¢‘(>1000)':<20} {very_high_trades:>10} {very_high_trades/total*100:>9.1f}%")
    
    print(f"\nå¹³å‡äº¤æ˜“æ•°: {np.mean(trade_counts):.1f}")
    print(f"ä¸­ä½æ•°äº¤æ˜“æ•°: {np.median(trade_counts):.1f}")
    print(f"æœ€å¤šäº¤æ˜“æ•°: {np.max(trade_counts)}")
    
    print(f"\nğŸ’¡ åˆ†æ:")
    if zero_trades / total > 0.5:
        print(f"   âš ï¸ è¶…è¿‡50%çš„Agentä¸äº¤æ˜“ï¼Œå¯èƒ½æ˜¯ç­–ç•¥è¿‡äºä¿å®ˆ")
        print(f"   å»ºè®®ï¼šè°ƒæ•´äº¤æ˜“é˜ˆå€¼æˆ–å¢åŠ æ¿€è¿›å‹Agent")
    else:
        print(f"   âœ… å¤§éƒ¨åˆ†Agentæœ‰äº¤æ˜“æ´»åŠ¨")
    
    conn.close()
    print("")


def analyze_pf_calculation_detail():
    """åˆ†æ7ï¼šPFè®¡ç®—ç»†èŠ‚ï¼ˆéªŒè¯è¶…é«˜PFçš„åˆç†æ€§ï¼‰"""
    print("\n" + "="*80)
    print("åˆ†æ7ï¼šè¶…é«˜PFçš„è®¡ç®—ç»†èŠ‚éªŒè¯")
    print("="*80 + "\n")
    
    print("ğŸ’¡ Profit Factorå…¬å¼: PF = total_profit / total_loss")
    print("")
    print("å¦‚æœ PF = 2,076,883.02ï¼Œå¯èƒ½çš„æƒ…å†µ:")
    print("")
    
    scenarios = [
        ("æƒ…å†µ1ï¼šæå°‘äºæŸ", 2076883.02, 1.0, "total_profit=$2,076,883, total_loss=$1"),
        ("æƒ…å†µ2ï¼šæ­£å¸¸ç›ˆåˆ©ï¼Œå¾®å°äºæŸ", 100.0, 0.048, "total_profit=$100, total_loss=$0.048"),
        ("æƒ…å†µ3ï¼šæå¤§ç›ˆåˆ©", 2000000.0, 1.0, "total_profit=$2,000,000, total_loss=$1"),
    ]
    
    print(f"{'æƒ…å†µ':<20} {'total_profit':>15} {'total_loss':>15} {'PF':>15}")
    print("-"*80)
    
    for name, profit, loss, _ in scenarios:
        pf = profit / loss if loss > 0 else profit
        print(f"{name:<20} ${profit:>14,.2f} ${loss:>14,.2f} {pf:>15,.2f}")
    
    print(f"\nğŸ’¡ åˆ†æ:")
    print(f"   PF = 2,076,883 è¯´æ˜:")
    print(f"   - è¦ä¹ˆtotal_lossæå°ï¼ˆæ¯”å¦‚åªäº$1ï¼‰")
    print(f"   - è¦ä¹ˆtotal_profitæå¤§ï¼ˆæ¯”å¦‚èµš$2,076,883ï¼‰")
    print(f"   - æˆ–è€…ä¸¤è€…éƒ½æœ‰")
    print(f"\n   å¦‚æœAgent ROI = +69,229% (ä»$750â†’$520,000):")
    print(f"   - æ€»ç›ˆåˆ©çº¦$519,250")
    print(f"   - å¦‚æœPF = 2,076,883ï¼Œåˆ™total_loss â‰ˆ $0.25")
    print(f"   - è¯´æ˜è¿™ä¸ªAgentå‡ ä¹åªæœ‰ç›ˆåˆ©äº¤æ˜“ï¼")
    
    print("")


def analyze_market_structure_impact():
    """åˆ†æ8ï¼šä¸åŒå¸‚åœºç»“æ„å¯¹Agentè¡¨ç°çš„å½±å“"""
    print("\n" + "="*80)
    print("åˆ†æ8ï¼šå¸‚åœºç»“æ„å½±å“åˆ†æ")
    print("="*80 + "\n")
    
    # åŠ è½½å¸‚åœºæ•°æ®
    try:
        market_data = pd.read_csv('data/stage1_1_training_market.csv')
        
        if 'structure_type' in market_data.columns:
            structures = market_data['structure_type'].unique()
            print(f"å¸‚åœºåŒ…å«çš„ç»“æ„: {list(structures)}\n")
            
            for structure in structures:
                structure_data = market_data[market_data['structure_type'] == structure]
                start_price = structure_data.iloc[0]['close']
                end_price = structure_data.iloc[-1]['close']
                roi = (end_price / start_price - 1) * 100
                
                print(f"{structure:15s}: {len(structure_data):>5} bars, "
                      f"ä»·æ ¼ ${start_price:>10,.2f} â†’ ${end_price:>10,.2f}, "
                      f"ROI {roi:>+8.2f}%")
            
            print(f"\nğŸ’¡ åˆ†æ:")
            print(f"   - trend_upåº”è¯¥åˆ©å¥½åšå¤šç­–ç•¥ï¼ˆbias>0.6ï¼‰")
            print(f"   - trend_downåº”è¯¥åˆ©å¥½åšç©ºç­–ç•¥ï¼ˆbias<0.4ï¼‰")
            print(f"   - rangeåº”è¯¥åˆ©å¥½å‡å€¼å›å½’ï¼ˆä¸­æ€§biasï¼‰")
            print(f"   - fake_breakoutéœ€è¦å¿«é€Ÿæ­¢æŸèƒ½åŠ›")
        else:
            print("âš ï¸ å¸‚åœºæ•°æ®ç¼ºå°‘structure_typeå­—æ®µ")
    
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½å¸‚åœºæ•°æ®: {e}")
    
    print("")


if __name__ == '__main__':
    print("\n" + "ğŸ”¬"*40)
    print("Stage 1.1 è®­ç»ƒç»“æœæ·±åº¦åˆ†æ")
    print("ğŸ”¬"*40)
    
    analyze_super_genes()
    analyze_excellent_genes()
    analyze_poor_performance()
    analyze_gene_evolution()
    analyze_pf_calculation_detail()
    analyze_market_structure_impact()
    
    print("\n" + "="*80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*80 + "\n")

