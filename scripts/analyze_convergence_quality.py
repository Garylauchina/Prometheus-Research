"""
æ”¶æ•›è´¨é‡åˆ†æï¼ˆv6.0è§†è§’ï¼‰
========================

åŸºäºæ–°ç†è§£ï¼š
  âœ… å¿«é€Ÿæ”¶æ•› = å¿«é€Ÿå“åº”èƒ½åŠ›
  âœ… æ–¹å‘å„æ–­ = æˆåŠŸé€‚åº”å¸‚åœº
  
åˆ†æç›®æ ‡ï¼š
1. æ”¶æ•›é€Ÿåº¦ï¼šå¤šå¿«æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥ï¼Ÿ
2. æ”¶æ•›è´¨é‡ï¼šæœ€ä¼˜ç­–ç•¥æ˜¯å¦çœŸçš„åŒ¹é…å¸‚åœºï¼Ÿ
3. æ·˜æ±°æ•ˆç‡ï¼šåŠ£è´¨åŸºå› æ¸…é™¤é€Ÿåº¦ï¼Ÿ
4. å¸‚åœºé€‚åº”æ€§ï¼šç­–ç•¥ä¸å¸‚åœºç»“æ„çš„åŒ¹é…åº¦ï¼Ÿ
5. æ”¹è¿›ç©ºé—´ï¼šå¦‚ä½•è®©æ”¶æ•›æ›´å¿«æ›´å‡†ï¼Ÿ
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import sqlite3
import json
import numpy as np
import pandas as pd
from collections import Counter


def analyze_convergence_speed():
    """åˆ†æ1ï¼šæ”¶æ•›é€Ÿåº¦ - å¤šå¿«æ‰¾åˆ°ä¼˜ç§€åŸºå› ï¼Ÿ"""
    print("\n" + "="*80)
    print("åˆ†æ1ï¼šæ”¶æ•›é€Ÿåº¦ - ç³»ç»Ÿçš„å­¦ä¹ æ›²çº¿")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æŒ‰å‘¨æœŸåˆ†ç»„ï¼Œçœ‹æ¯ä¸ªå‘¨æœŸçš„æœ€ä½³è¡¨ç°
    cursor = conn.execute("""
        SELECT 
            run_id,
            MAX(profit_factor) as max_pf,
            AVG(profit_factor) as avg_pf,
            MAX(roi) as max_roi,
            AVG(roi) as avg_roi
        FROM best_genomes
        GROUP BY run_id
        ORDER BY run_id
    """)
    
    records = list(cursor)
    
    # æå–å‘¨æœŸæ•°
    cycles = []
    max_pfs = []
    avg_pfs = []
    max_rois = []
    
    for run_id, max_pf, avg_pf, max_roi, avg_roi in records:
        if '_cycle' in run_id:
            cycle = int(run_id.split('_cycle')[-1])
            cycles.append(cycle)
            max_pfs.append(max_pf)
            avg_pfs.append(avg_pf)
            max_rois.append(max_roi)
    
    if not cycles:
        print("âš ï¸ æ— æ³•æå–å‘¨æœŸä¿¡æ¯")
        conn.close()
        return
    
    print(f"è®­ç»ƒå‘¨æœŸèŒƒå›´: {min(cycles)} - {max(cycles)}")
    print(f"ä¿å­˜æ¬¡æ•°: {len(cycles)}\n")
    
    # æ‰¾åˆ°å…³é”®æ—¶é—´ç‚¹
    print("ã€å…³é”®æ—¶é—´ç‚¹ã€‘")
    print(f"{'é˜¶æ®µ':<30} {'å‘¨æœŸ':>10} {'æœ€é«˜PF':>15} {'æœ€é«˜ROI':>12}")
    print("-"*80)
    
    # ç¬¬ä¸€æ¬¡å‡ºç°PF > 0
    first_profit_idx = next((i for i, pf in enumerate(max_pfs) if pf > 0), None)
    if first_profit_idx is not None:
        print(f"{'é¦–æ¬¡å‡ºç°ç›ˆåˆ©åŸºå› ':<30} {cycles[first_profit_idx]:>10} {max_pfs[first_profit_idx]:>15,.2f} {max_rois[first_profit_idx]*100:>11.2f}%")
    
    # ç¬¬ä¸€æ¬¡å‡ºç°PF > 1.0
    first_good_idx = next((i for i, pf in enumerate(max_pfs) if pf > 1.0), None)
    if first_good_idx is not None:
        print(f"{'é¦–æ¬¡å‡ºç°ä¼˜ç§€åŸºå› (PF>1.0)':<30} {cycles[first_good_idx]:>10} {max_pfs[first_good_idx]:>15,.2f} {max_rois[first_good_idx]*100:>11.2f}%")
    
    # ç¬¬ä¸€æ¬¡å‡ºç°PF > 2.0
    first_excellent_idx = next((i for i, pf in enumerate(max_pfs) if pf > 2.0), None)
    if first_excellent_idx is not None:
        print(f"{'é¦–æ¬¡å‡ºç°å“è¶ŠåŸºå› (PF>2.0)':<30} {cycles[first_excellent_idx]:>10} {max_pfs[first_excellent_idx]:>15,.2f} {max_rois[first_excellent_idx]*100:>11.2f}%")
    
    # è¾¾åˆ°å³°å€¼
    peak_idx = max_pfs.index(max(max_pfs))
    print(f"{'è¾¾åˆ°å³°å€¼æ€§èƒ½':<30} {cycles[peak_idx]:>10} {max_pfs[peak_idx]:>15,.2f} {max_rois[peak_idx]*100:>11.2f}%")
    
    # æœ€åä¸€è½®
    print(f"{'æœ€åä¸€è½®':<30} {cycles[-1]:>10} {max_pfs[-1]:>15,.2f} {max_rois[-1]*100:>11.2f}%")
    
    print(f"\nğŸ’¡ æ”¶æ•›é€Ÿåº¦è¯„ä¼°:")
    if first_excellent_idx is not None and cycles[first_excellent_idx] < 500:
        print(f"   âœ… ä¼˜ç§€ï¼åœ¨{cycles[first_excellent_idx]}å‘¨æœŸå°±æ‰¾åˆ°å“è¶ŠåŸºå› ")
        print(f"   âœ… å“åº”é€Ÿåº¦ï¼š< 500å‘¨æœŸ")
    elif first_excellent_idx is not None and cycles[first_excellent_idx] < 1000:
        print(f"   âš ï¸ è‰¯å¥½ã€‚åœ¨{cycles[first_excellent_idx]}å‘¨æœŸæ‰¾åˆ°å“è¶ŠåŸºå› ")
        print(f"   âš ï¸ å“åº”é€Ÿåº¦ï¼š500-1000å‘¨æœŸ")
    elif first_excellent_idx is None:
        print(f"   âŒ è¾ƒæ…¢ã€‚æ•´ä¸ªè®­ç»ƒæœŸé—´æœªå‡ºç°PF>2.0çš„åŸºå› ")
        print(f"   âŒ éœ€è¦ä¼˜åŒ–è¿›åŒ–å‚æ•°")
    
    # æ£€æŸ¥æ˜¯å¦æŒç»­æ”¹è¿›
    print(f"\nã€æŒç»­æ”¹è¿›è¶‹åŠ¿ã€‘")
    if len(max_pfs) >= 3:
        early_avg = np.mean(max_pfs[:len(max_pfs)//3])
        mid_avg = np.mean(max_pfs[len(max_pfs)//3:2*len(max_pfs)//3])
        late_avg = np.mean(max_pfs[2*len(max_pfs)//3:])
        
        print(f"å‰1/3å‘¨æœŸå¹³å‡æœ€é«˜PF: {early_avg:,.2f}")
        print(f"ä¸­1/3å‘¨æœŸå¹³å‡æœ€é«˜PF: {mid_avg:,.2f}")
        print(f"å1/3å‘¨æœŸå¹³å‡æœ€é«˜PF: {late_avg:,.2f}")
        
        if late_avg > mid_avg > early_avg:
            print(f"\nâœ… æŒç»­æ”¹è¿›ï¼ç³»ç»Ÿåœ¨ä¸æ–­å­¦ä¹ ")
        elif late_avg > early_avg:
            print(f"\nâš ï¸ æœ‰æ”¹è¿›ï¼Œä½†ä¸­æœŸå¯èƒ½æœ‰æ³¢åŠ¨")
        else:
            print(f"\nâŒ æœªè§æ˜æ˜¾æ”¹è¿›ï¼Œå¯èƒ½å·²è¾¾ç“¶é¢ˆæˆ–å‚æ•°ä¸å½“")
    
    conn.close()
    print("")


def analyze_convergence_direction():
    """åˆ†æ2ï¼šæ”¶æ•›æ–¹å‘ - æ˜¯å¦åŒ¹é…å¸‚åœºç‰¹å¾ï¼Ÿ"""
    print("\n" + "="*80)
    print("åˆ†æ2ï¼šæ”¶æ•›æ–¹å‘æ­£ç¡®æ€§ - ç­–ç•¥æ˜¯å¦åŒ¹é…å¸‚åœºï¼Ÿ")
    print("="*80 + "\n")
    
    # åŠ è½½å¸‚åœºæ•°æ®
    try:
        market_data = pd.read_csv('data/stage1_1_training_market.csv')
        
        # è®¡ç®—æ¯ä¸ªç»“æ„çš„ç‰¹å¾
        print("ã€å¸‚åœºç»“æ„åˆ†æã€‘")
        print(f"{'ç»“æ„ç±»å‹':<15} {'å æ¯”':>8} {'ä»·æ ¼å˜åŒ–':>12} {'ç†æƒ³ç­–ç•¥':>15}")
        print("-"*80)
        
        if 'structure_type' in market_data.columns:
            structures = market_data['structure_type'].unique()
            
            structure_impact = {}
            for structure in structures:
                structure_data = market_data[market_data['structure_type'] == structure]
                start_price = structure_data.iloc[0]['close']
                end_price = structure_data.iloc[-1]['close']
                roi = (end_price / start_price - 1) * 100
                weight = len(structure_data) / len(market_data)
                
                structure_impact[structure] = {
                    'weight': weight,
                    'roi': roi
                }
                
                ideal_strategy = ""
                if 'up' in structure:
                    ideal_strategy = "åšå¤š(bias>0.6)"
                elif 'down' in structure:
                    ideal_strategy = "åšç©º(bias<0.4)"
                elif 'range' in structure:
                    ideal_strategy = "ä¸­æ€§(biasâ‰ˆ0.5)"
                elif 'fake' in structure:
                    ideal_strategy = "å¿«è¿›å¿«å‡º"
                
                print(f"{structure:<15} {weight*100:>7.1f}% {roi:>+11.2f}% {ideal_strategy:>15}")
        else:
            print("âš ï¸ å¸‚åœºæ•°æ®ç¼ºå°‘structure_typeå­—æ®µ")
            return
        
        # è®¡ç®—åŠ æƒæœ€ä¼˜æ–¹å‘
        print(f"\nã€åŠ æƒæœ€ä¼˜ç­–ç•¥è®¡ç®—ã€‘")
        
        # ç®€åŒ–è®¡ç®—ï¼šå“ªä¸ªæ–¹å‘çš„åŠ æƒæ”¶ç›Šæœ€é«˜ï¼Ÿ
        weighted_up_roi = sum(
            info['weight'] * info['roi']
            for struct, info in structure_impact.items()
            if 'up' in struct
        )
        weighted_down_roi = sum(
            info['weight'] * abs(info['roi'])  # åšç©ºæ—¶ï¼Œä¸‹è·Œæ˜¯ç›ˆåˆ©
            for struct, info in structure_impact.items()
            if 'down' in struct
        )
        
        print(f"åšå¤šåŠ æƒæ”¶ç›Š: {weighted_up_roi:+.2f}%")
        print(f"åšç©ºåŠ æƒæ”¶ç›Š: {weighted_down_roi:+.2f}%")
        
        optimal_bias = "åšç©º(bias<0.4)" if weighted_down_roi > weighted_up_roi else "åšå¤š(bias>0.6)"
        print(f"\nç†è®ºæœ€ä¼˜ç­–ç•¥: {optimal_bias}")
        
        # å¯¹æ¯”å®é™…æ”¶æ•›ç»“æœ
        print(f"\nã€å®é™…æ”¶æ•›ç»“æœã€‘")
        
        conn = sqlite3.connect('experience/stage1_1_full_training.db')
        cursor = conn.execute("""
            SELECT genome 
            FROM best_genomes
            WHERE profit_factor >= 2.0
        """)
        
        excellent_genes = []
        for row in cursor:
            genome = json.loads(row[0])
            excellent_genes.append(genome)
        
        if excellent_genes:
            avg_bias = np.mean([g['directional_bias'] for g in excellent_genes])
            print(f"ä¼˜ç§€åŸºå› å¹³å‡bias: {avg_bias:.3f}")
            
            actual_strategy = ""
            if avg_bias < 0.4:
                actual_strategy = "åšç©º(bias<0.4)"
            elif avg_bias > 0.6:
                actual_strategy = "åšå¤š(bias>0.6)"
            else:
                actual_strategy = "ä¸­æ€§(biasâ‰ˆ0.5)"
            
            print(f"å®é™…æ”¶æ•›ç­–ç•¥: {actual_strategy}")
            
            print(f"\nğŸ’¡ æ–¹å‘åŒ¹é…åº¦è¯„ä¼°:")
            if (weighted_down_roi > weighted_up_roi and avg_bias < 0.4) or \
               (weighted_down_roi < weighted_up_roi and avg_bias > 0.6):
                print(f"   âœ… å®Œç¾åŒ¹é…ï¼ç³»ç»Ÿæ­£ç¡®è¯†åˆ«äº†å¸‚åœºç‰¹å¾")
                print(f"   âœ… æ”¶æ•›æ–¹å‘ä¸ç†è®ºæœ€ä¼˜ä¸€è‡´")
            else:
                print(f"   âš ï¸ æ–¹å‘åå·®ï¼ç³»ç»Ÿå¯èƒ½æœªå……åˆ†å­¦ä¹ ")
                print(f"   âš ï¸ å»ºè®®ï¼šå»¶é•¿è®­ç»ƒæˆ–è°ƒæ•´å‚æ•°")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä¼˜ç§€åŸºå› ï¼ˆPFâ‰¥2.0ï¼‰")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
    
    print("")


def analyze_elimination_efficiency():
    """åˆ†æ3ï¼šæ·˜æ±°æ•ˆç‡ - åŠ£è´¨åŸºå› æ˜¯å¦è¢«å¿«é€Ÿæ¸…é™¤ï¼Ÿ"""
    print("\n" + "="*80)
    print("åˆ†æ3ï¼šæ·˜æ±°æ•ˆç‡ - è‡ªç„¶é€‰æ‹©çš„æœ‰æ•ˆæ€§")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æŒ‰å‘¨æœŸç»Ÿè®¡ä¸åŒè¡¨ç°ç­‰çº§çš„åŸºå› æ•°é‡
    cursor = conn.execute("""
        SELECT 
            run_id,
            SUM(CASE WHEN profit_factor >= 2.0 THEN 1 ELSE 0 END) as excellent_count,
            SUM(CASE WHEN profit_factor >= 1.0 AND profit_factor < 2.0 THEN 1 ELSE 0 END) as good_count,
            SUM(CASE WHEN profit_factor > 0 AND profit_factor < 1.0 THEN 1 ELSE 0 END) as losing_count,
            SUM(CASE WHEN profit_factor = 0 AND trade_count > 0 THEN 1 ELSE 0 END) as bad_count,
            SUM(CASE WHEN trade_count = 0 THEN 1 ELSE 0 END) as inactive_count
        FROM best_genomes
        GROUP BY run_id
        ORDER BY run_id
    """)
    
    records = list(cursor)
    
    if len(records) < 3:
        print("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿")
        conn.close()
        return
    
    print("ã€åŸºå› è´¨é‡åˆ†å¸ƒè¶‹åŠ¿ã€‘")
    print(f"{'å‘¨æœŸ':<10} {'ä¼˜ç§€':>8} {'è‰¯å¥½':>8} {'äºæŸ':>8} {'åŠ£è´¨':>8} {'ä¸æ´»è·ƒ':>10}")
    print("-"*80)
    
    # æå–å‘¨æœŸä¿¡æ¯
    cycles_data = []
    for run_id, exc, good, losing, bad, inactive in records:
        if '_cycle' in run_id:
            cycle = int(run_id.split('_cycle')[-1])
            cycles_data.append((cycle, exc, good, losing, bad, inactive))
    
    # æ˜¾ç¤ºå…³é”®å‘¨æœŸ
    if cycles_data:
        # é¦–è½®
        cycle, exc, good, losing, bad, inactive = cycles_data[0]
        print(f"Cycle{cycle:<5} {exc:>8} {good:>8} {losing:>8} {bad:>8} {inactive:>10}")
        
        # ä¸­é—´ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if len(cycles_data) > 10:
            print("   ...")
            mid = len(cycles_data) // 2
            cycle, exc, good, losing, bad, inactive = cycles_data[mid]
            print(f"Cycle{cycle:<5} {exc:>8} {good:>8} {losing:>8} {bad:>8} {inactive:>10}")
            print("   ...")
        
        # æœ€åä¸€è½®
        cycle, exc, good, losing, bad, inactive = cycles_data[-1]
        print(f"Cycle{cycle:<5} {exc:>8} {good:>8} {losing:>8} {bad:>8} {inactive:>10}")
    
    print(f"\nğŸ’¡ æ·˜æ±°æ•ˆç‡è¯„ä¼°:")
    
    # è®¡ç®—è¶‹åŠ¿
    if len(cycles_data) >= 3:
        early_inactive = np.mean([data[5] for data in cycles_data[:len(cycles_data)//3]])
        late_inactive = np.mean([data[5] for data in cycles_data[2*len(cycles_data)//3:]])
        
        early_excellent = np.mean([data[1] for data in cycles_data[:len(cycles_data)//3]])
        late_excellent = np.mean([data[1] for data in cycles_data[2*len(cycles_data)//3:]])
        
        print(f"   ä¸æ´»è·ƒåŸºå› : å‰æœŸ{early_inactive:.1f} â†’ åæœŸ{late_inactive:.1f}")
        print(f"   ä¼˜ç§€åŸºå› :   å‰æœŸ{early_excellent:.1f} â†’ åæœŸ{late_excellent:.1f}")
        
        if late_inactive < early_inactive and late_excellent > early_excellent:
            print(f"\n   âœ… æ·˜æ±°æœ‰æ•ˆï¼åŠ£è´¨åŸºå› â†“ï¼Œä¼˜ç§€åŸºå› â†‘")
        elif late_inactive < early_inactive:
            print(f"\n   âš ï¸ æ·˜æ±°æœ‰æ•ˆä½†ä¼˜ç§€åŸºå› æœªå¢åŠ ")
            print(f"   å»ºè®®ï¼šå¢åŠ ç¹æ®–ç‡æˆ–é™ä½æ·˜æ±°ç‡")
        else:
            print(f"\n   âŒ æ·˜æ±°æ•ˆç‡ä½ï¼åŠ£è´¨åŸºå› æœªè¢«æœ‰æ•ˆæ¸…é™¤")
            print(f"   å»ºè®®ï¼šæé«˜æ·˜æ±°ç‡æˆ–ç¼©çŸ­è¿›åŒ–é—´éš”")
    
    conn.close()
    print("")


def analyze_inactive_agents():
    """åˆ†æ4ï¼šä¸æ´»è·ƒAgent - æ˜¯å‚æ•°é—®é¢˜è¿˜æ˜¯è¿›åŒ–é—®é¢˜ï¼Ÿ"""
    print("\n" + "="*80)
    print("åˆ†æ4ï¼šä¸æ´»è·ƒAgentæ·±åº¦åˆ†æï¼ˆ57.2%ä¸äº¤æ˜“ï¼‰")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æå–ä¸æ´»è·ƒAgentçš„å‚æ•°ç‰¹å¾
    cursor = conn.execute("""
        SELECT genome FROM best_genomes
        WHERE trade_count = 0
    """)
    
    inactive_genomes = []
    for row in cursor:
        genome = json.loads(row[0])
        inactive_genomes.append(genome)
    
    if not inactive_genomes:
        print("âœ… æ²¡æœ‰ä¸æ´»è·ƒAgent")
        conn.close()
        return
    
    # å¯¹æ¯”æ´»è·ƒAgent
    cursor = conn.execute("""
        SELECT genome FROM best_genomes
        WHERE trade_count > 0
    """)
    
    active_genomes = []
    for row in cursor:
        genome = json.loads(row[0])
        active_genomes.append(genome)
    
    print(f"ä¸æ´»è·ƒAgentæ•°é‡: {len(inactive_genomes)}")
    print(f"æ´»è·ƒAgentæ•°é‡: {len(active_genomes)}\n")
    
    # ç»Ÿè®¡å‚æ•°å·®å¼‚
    print("ã€å‚æ•°å¯¹æ¯”ï¼šä¸æ´»è·ƒ vs æ´»è·ƒã€‘")
    print(f"{'å‚æ•°':<30} {'ä¸æ´»è·ƒå¹³å‡':>15} {'æ´»è·ƒå¹³å‡':>15} {'å·®å¼‚':>10}")
    print("-"*80)
    
    param_keys = [k for k in inactive_genomes[0].keys() if k != 'generation']
    
    for key in param_keys:
        inactive_values = [g.get(key, 0) for g in inactive_genomes]
        active_values = [g.get(key, 0) for g in active_genomes]
        
        inactive_mean = np.mean(inactive_values)
        active_mean = np.mean(active_values)
        diff = active_mean - inactive_mean
        
        marker = ""
        if abs(diff) > 0.15:
            marker = " â­" if diff > 0 else " âš ï¸"
        
        print(f"{key:<30} {inactive_mean:>15.3f} {active_mean:>15.3f} {diff:>+10.3f}{marker}")
    
    print(f"\nğŸ’¡ ä¸æ´»è·ƒåŸå› åˆ†æ:")
    
    # æ£€æŸ¥å…³é”®å‚æ•°
    inactive_bias = np.mean([g['directional_bias'] for g in inactive_genomes])
    active_bias = np.mean([g['directional_bias'] for g in active_genomes])
    
    if abs(inactive_bias - active_bias) < 0.1:
        print(f"   âš ï¸ æ–¹å‘åå¥½æ¥è¿‘ï¼ˆinactive={inactive_bias:.3f}, active={active_bias:.3f}ï¼‰")
        print(f"   å¯èƒ½åŸå› ï¼šå…¶ä»–å‚æ•°å¯¼è‡´ä¸äº¤æ˜“")
    
    # æ£€æŸ¥holding_preference
    inactive_hold = np.mean([g['holding_preference'] for g in inactive_genomes])
    active_hold = np.mean([g['holding_preference'] for g in active_genomes])
    
    if inactive_hold > active_hold + 0.1:
        print(f"   âš ï¸ ä¸æ´»è·ƒAgentæŒä»“åå¥½æ›´é«˜ï¼ˆ{inactive_hold:.3f} vs {active_hold:.3f}ï¼‰")
        print(f"   å¯èƒ½ï¼šæŒä»“åå¥½è¿‡é«˜å¯¼è‡´ä»ä¸å¼€ä»“")
    
    # æ£€æŸ¥stop_losså’Œtake_profit
    inactive_sl = np.mean([g['stop_loss_threshold'] for g in inactive_genomes])
    active_sl = np.mean([g['stop_loss_threshold'] for g in active_genomes])
    
    if abs(inactive_sl - active_sl) > 0.15:
        print(f"   âš ï¸ æ­¢æŸé˜ˆå€¼å·®å¼‚å¤§ï¼ˆinactive={inactive_sl:.3f}, active={active_sl:.3f}ï¼‰")
        print(f"   å¯èƒ½ï¼šé˜ˆå€¼è®¾ç½®è¿‡ä¸¥ï¼Œæ°¸è¿œä¸æ»¡è¶³äº¤æ˜“æ¡ä»¶")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"   1. è¿™äº›ä¸æ´»è·ƒAgentåº”è¯¥è¢«æ›´å¿«æ·˜æ±°ï¼ˆå½“å‰å¯èƒ½å­˜æ´»è¿‡ä¹…ï¼‰")
    print(f"   2. æ£€æŸ¥äº¤æ˜“ä¿¡å·ç”Ÿæˆé€»è¾‘ï¼ˆInnerCouncil._strategy_voiceï¼‰")
    print(f"   3. è€ƒè™‘æ·»åŠ 'äº¤æ˜“æ•°æƒ©ç½š'ï¼štrade_count=0çš„Agent fitnesså¤§å¹…é™ä½")
    
    conn.close()
    print("")


def analyze_convergence_quality():
    """åˆ†æ5ï¼šæ”¶æ•›è´¨é‡ - æœ€ç»ˆåŸºå› çš„ç«äº‰åŠ›"""
    print("\n" + "="*80)
    print("åˆ†æ5ï¼šæ”¶æ•›è´¨é‡ - æœ€ç»ˆåŸºå› èƒ½å¦å®æˆ˜ï¼Ÿ")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('experience/stage1_1_full_training.db')
    
    # æå–TopåŸºå› 
    cursor = conn.execute("""
        SELECT roi, profit_factor, trade_count, genome
        FROM best_genomes
        WHERE profit_factor >= 2.0
        ORDER BY profit_factor DESC
    """)
    
    top_genes = []
    for roi, pf, trade_count, genome_str in cursor:
        genome = json.loads(genome_str)
        top_genes.append({
            'roi': roi,
            'pf': pf,
            'trade_count': trade_count,
            'genome': genome
        })
    
    if not top_genes:
        print("âŒ æœªæ‰¾åˆ°ä¼˜ç§€åŸºå› ï¼ˆPFâ‰¥2.0ï¼‰")
        print("   ç³»ç»Ÿå¯èƒ½æœªæˆåŠŸæ”¶æ•›")
        conn.close()
        return
    
    print(f"æ‰¾åˆ° {len(top_genes)} ä¸ªä¼˜ç§€åŸºå› \n")
    
    print("ã€Top 5 åŸºå› è¯¦æƒ…ã€‘")
    for i, gene in enumerate(top_genes[:5]):
        print(f"\nåŸºå›  #{i+1}")
        print(f"  ROI: {gene['roi']*100:+.2f}%")
        print(f"  PF: {gene['pf']:,.2f}")
        print(f"  äº¤æ˜“æ•°: {gene['trade_count']}")
        print(f"  ç­–ç•¥:")
        print(f"    æ–¹å‘åå¥½: {gene['genome']['directional_bias']:.3f}", end="")
        if gene['genome']['directional_bias'] < 0.4:
            print(" (åç©º)")
        elif gene['genome']['directional_bias'] > 0.6:
            print(" (åå¤š)")
        else:
            print(" (ä¸­æ€§)")
        print(f"    æŒä»“åå¥½: {gene['genome']['holding_preference']:.3f}")
        print(f"    ä»“ä½å¤§å°: {gene['genome']['position_size_base']:.3f}")
        print(f"    æ­¢æŸé˜ˆå€¼: {gene['genome']['stop_loss_threshold']:.3f}")
        print(f"    æ­¢ç›ˆé˜ˆå€¼: {gene['genome']['take_profit_threshold']:.3f}")
    
    # è¯„ä¼°åŸºå› è´¨é‡
    print(f"\n{'='*80}")
    print("ã€åŸºå› è´¨é‡è¯„ä¼°ã€‘")
    print(f"{'='*80}\n")
    
    avg_roi = np.mean([g['roi'] for g in top_genes])
    avg_pf = np.mean([g['pf'] for g in top_genes])
    avg_trades = np.mean([g['trade_count'] for g in top_genes])
    
    print(f"å¹³å‡ROI: {avg_roi*100:+.2f}%")
    print(f"å¹³å‡PF: {avg_pf:,.2f}")
    print(f"å¹³å‡äº¤æ˜“æ•°: {avg_trades:.0f}")
    
    print(f"\nğŸ’¡ è´¨é‡è¯„çº§:")
    
    score = 0
    feedback = []
    
    # ROIè¯„åˆ†
    if avg_roi > 5.0:
        score += 3
        feedback.append("âœ… ROIä¼˜ç§€ (+3åˆ†)")
    elif avg_roi > 1.0:
        score += 2
        feedback.append("âš ï¸ ROIè‰¯å¥½ (+2åˆ†)")
    elif avg_roi > 0.5:
        score += 1
        feedback.append("âš ï¸ ROIä¸€èˆ¬ (+1åˆ†)")
    else:
        feedback.append("âŒ ROIè¾ƒä½ (0åˆ†)")
    
    # PFè¯„åˆ†
    if avg_pf > 2.0:
        score += 3
        feedback.append("âœ… PFä¼˜ç§€ (+3åˆ†)")
    elif avg_pf > 1.5:
        score += 2
        feedback.append("âš ï¸ PFè‰¯å¥½ (+2åˆ†)")
    elif avg_pf > 1.0:
        score += 1
        feedback.append("âš ï¸ PFä¸€èˆ¬ (+1åˆ†)")
    else:
        feedback.append("âŒ PFä¸è¶³ (0åˆ†)")
    
    # äº¤æ˜“æ´»è·ƒåº¦è¯„åˆ†
    if avg_trades > 100:
        score += 2
        feedback.append("âœ… äº¤æ˜“æ´»è·ƒ (+2åˆ†)")
    elif avg_trades > 10:
        score += 1
        feedback.append("âš ï¸ äº¤æ˜“ä¸€èˆ¬ (+1åˆ†)")
    else:
        feedback.append("âŒ äº¤æ˜“è¿‡å°‘ (0åˆ†)")
    
    # åŸºå› å¤šæ ·æ€§è¯„åˆ†ï¼ˆçœ‹TopåŸºå› æ˜¯å¦å¤ªç›¸ä¼¼ï¼‰
    if len(top_genes) > 1:
        biases = [g['genome']['directional_bias'] for g in top_genes]
        bias_std = np.std(biases)
        
        if bias_std > 0.1:
            score += 2
            feedback.append("âœ… ä¿æŒå¤šæ ·æ€§ (+2åˆ†)")
        else:
            score += 1
            feedback.append("âš ï¸ åŸºå› ç›¸ä¼¼ (+1åˆ†)")
    
    for line in feedback:
        print(f"   {line}")
    
    print(f"\n   æ€»åˆ†: {score}/10")
    
    if score >= 9:
        print(f"   è¯„çº§: â­â­â­â­â­ å“è¶Šï¼å¯ç›´æ¥ç”¨äºå®æˆ˜")
    elif score >= 7:
        print(f"   è¯„çº§: â­â­â­â­ ä¼˜ç§€ï¼é€‚åˆè¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
    elif score >= 5:
        print(f"   è¯„çº§: â­â­â­ è‰¯å¥½ï¼Œä½†éœ€è¦æ”¹è¿›")
    else:
        print(f"   è¯„çº§: â­â­ ä¸€èˆ¬ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæˆ–è°ƒå‚")
    
    conn.close()
    print("")


if __name__ == '__main__':
    print("\n" + "ğŸ¯"*40)
    print("Stage 1.1 æ”¶æ•›è´¨é‡åˆ†æï¼ˆv6.0è§†è§’ï¼šå¿«é€Ÿæ”¶æ•›=å¿«é€Ÿå“åº”ï¼‰")
    print("ğŸ¯"*40)
    
    analyze_convergence_speed()
    analyze_convergence_direction()
    analyze_elimination_efficiency()
    analyze_inactive_agents()
    analyze_convergence_quality()
    
    print("\n" + "="*80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*80 + "\n")

