"""
Stage 1.1 å®Œæ•´è®­ç»ƒè„šæœ¬
======================

ç›®æ ‡ï¼š
1. è¿è¡Œ5000å‘¨æœŸå®Œæ•´è®­ç»ƒ
2. éªŒè¯PFä¸»å¯¼+Immigration+å¢å¼ºçªå˜çš„ç»¼åˆæ•ˆæœ
3. è®°å½•è¯¦ç»†çš„è¿›åŒ–è¿‡ç¨‹
4. åˆ†æåŸºå› æ”¶æ•›å’Œå¤šæ ·æ€§

é…ç½®ï¼š
- å¸‚åœº: stage1_switchingï¼ˆ4ç§ç»“æ„åˆ‡æ¢ï¼‰
- å‘¨æœŸ: 5000
- Agent: 50
- Fitness: Profit Factorä¸»å¯¼
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import pandas as pd
import numpy as np
from datetime import datetime
from prometheus.facade.v6_facade import V6Facade
from prometheus.config.mock_training_config import MockTrainingConfig


def run_full_training():
    """è¿è¡Œå®Œæ•´è®­ç»ƒ"""
    
    print("\n" + "="*80)
    print("ğŸš€ Stage 1.1 å®Œæ•´è®­ç»ƒ")
    print("="*80 + "\n")
    
    # ========== 1. ç”Ÿæˆè®­ç»ƒå¸‚åœº ==========
    print("ğŸ“Š Step 1: ç”Ÿæˆè®­ç»ƒå¸‚åœºæ•°æ®")
    print("-"*80)
    
    facade = V6Facade()
    
    market_data = facade.generate_training_market(
        market_type='stage1_switching',
        total_bars=5000,
        structures=['trend_up', 'range', 'trend_down', 'fake_breakout'],
        bars_per_structure=1250,  # æ¯ç§ç»“æ„1250 bars
        random_seed=42,
        save_path='data/stage1_1_training_market.csv'
    )
    
    print(f"âœ… å¸‚åœºæ•°æ®ç”Ÿæˆå®Œæˆ: {len(market_data)} bars")
    print(f"   ä»·æ ¼èŒƒå›´: [{market_data['close'].min():.2f}, {market_data['close'].max():.2f}]")
    
    # ç»Ÿè®¡å¸‚åœºç»“æ„åˆ†å¸ƒ
    if 'structure_type' in market_data.columns:
        structure_dist = market_data['structure_type'].value_counts()
        print(f"\n   å¸‚åœºç»“æ„åˆ†å¸ƒ:")
        for structure, count in structure_dist.items():
            print(f"   - {structure}: {count} bars ({count/len(market_data)*100:.1f}%)")
    
    print("")
    
    # ========== 2. é…ç½®è®­ç»ƒå‚æ•° ==========
    print("âš™ï¸  Step 2: é…ç½®è®­ç»ƒå‚æ•°")
    print("-"*80)
    
    config = MockTrainingConfig(
        # åŸºç¡€é…ç½®
        cycles=5000,
        total_system_capital=500000.0,  # 50ä¸‡åˆå§‹èµ„é‡‘
        agent_count=50,
        
        # åˆ›ä¸–é…ç½®
        genesis_allocation_ratio=0.3,  # 30%ç»™Agentï¼Œ70%èµ„é‡‘æ± 
        genesis_strategy='random',  # çº¯éšæœºåˆ›ä¸–ï¼ˆStage 1æµ‹è¯•åŸºå› è¿›åŒ–ï¼‰
        
        # è¿›åŒ–é…ç½®
        evolution_interval=50,  # æ¯50å‘¨æœŸè¿›åŒ–ä¸€æ¬¡
        elimination_rate=0.3,  # æ·˜æ±°30%
        elite_ratio=0.2,  # ä¿ç•™20%ç²¾è‹±
        fitness_mode='profit_factor',  # âœ… Stage 1.1: PFä¸»å¯¼
        
        # å¸‚åœºé…ç½®
        market_type='stage1_switching',
        
        # ç»éªŒåº“é…ç½®
        experience_db_path='experience/stage1_1_full_training.db',
        top_k_to_save=20,  # ä¿å­˜å‰20å
        save_experience_interval=50,  # æ¯50å‘¨æœŸä¿å­˜ä¸€æ¬¡
        
        # æ—¥å¿—é…ç½®
        log_dir='logs/stage1_1_full_training',
        log_interval=100,
        enable_debug_log=False
    )
    
    print(f"âœ… è®­ç»ƒé…ç½®:")
    print(f"   å‘¨æœŸæ•°: {config.cycles}")
    print(f"   ç³»ç»Ÿèµ„é‡‘: ${config.total_system_capital:,.0f}")
    print(f"   Agentæ•°é‡: {config.agent_count}")
    print(f"   Fitnessæ¨¡å¼: {config.fitness_mode} âœ…")
    print(f"   è¿›åŒ–é—´éš”: {config.evolution_interval}")
    print(f"   æ·˜æ±°ç‡: {config.elimination_rate*100:.0f}%")
    print(f"   ç²¾è‹±æ¯”ä¾‹: {config.elite_ratio*100:.0f}%")
    print("")
    
    # ========== 3. è¿è¡Œè®­ç»ƒ ==========
    print("ğŸƒ Step 3: å¼€å§‹è®­ç»ƒ")
    print("-"*80)
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("")
    
    start_time = datetime.now()
    
    result = facade.run_mock_training(
        config=config,
        market_data=market_data
    )
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    print("")
    print("-"*80)
    print(f"   ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   è®­ç»ƒè€—æ—¶: {duration/60:.1f}åˆ†é’Ÿ ({duration:.0f}ç§’)")
    print("")
    
    # ========== 4. åˆ†æç»“æœ ==========
    print("ğŸ“Š Step 4: è®­ç»ƒç»“æœåˆ†æ")
    print("="*80)
    
    print(f"\nã€ç³»ç»Ÿçº§æŒ‡æ ‡ã€‘")
    print(f"  ç³»ç»ŸROI: {result.system_roi*100:+.2f}%")
    print(f"  ç³»ç»Ÿæ€»èµ„äº§: ${result.system_total_capital:,.2f}")
    print(f"  BTCåŸºå‡†ROI: {result.btc_benchmark_roi*100:+.2f}%")
    print(f"  è¶…è¶ŠBTC: {result.outperformance*100:+.2f}%")
    
    print(f"\nã€Agentçº§æŒ‡æ ‡ã€‘")
    print(f"  æœ€ç»ˆAgentæ•°: {result.agent_count_final}")
    print(f"  æœ€ä½³ROI: {result.agent_best_roi*100:+.2f}%")
    print(f"  å¹³å‡ROI: {result.agent_avg_roi*100:+.2f}%")
    print(f"  ä¸­ä½æ•°ROI: {result.agent_median_roi*100:+.2f}%")
    print(f"  å¹³å‡äº¤æ˜“æ•°: {result.agent_avg_trade_count:.1f}")
    
    print(f"\nã€èµ„é‡‘æ± çŠ¶æ€ã€‘")
    print(f"  èµ„é‡‘æ± ä½™é¢: ${result.capital_pool_balance:,.2f}")
    print(f"  èµ„é‡‘åˆ©ç”¨ç‡: {result.capital_utilization*100:.1f}%")
    
    print(f"\nã€å¯¹è´¦éªŒè¯ã€‘")
    print(f"  å¯¹è´¦çŠ¶æ€: {'âœ… é€šè¿‡' if result.reconciliation_passed else 'âŒ å¤±è´¥'}")
    
    print(f"\nã€ç»éªŒåº“ã€‘")
    print(f"  æ€»è®°å½•æ•°: {result.experience_db_records}")
    print(f"  æœ¬æ¬¡ä¿å­˜: {'âœ… æ˜¯' if result.experience_saved else 'âŒ å¦'}")
    
    print("")
    
    # ========== 5. åˆ†æExperienceDB ==========
    if facade.experience_db and result.experience_db_records > 0:
        print("ğŸ“Š Step 5: åŸºå› æ•°æ®åˆ†æ")
        print("="*80)
        
        import sqlite3
        conn = sqlite3.connect(config.experience_db_path)
        
        # 5.1 Profit Factoråˆ†å¸ƒ
        print(f"\nã€Profit Factoråˆ†å¸ƒã€‘")
        cursor = conn.execute("""
            SELECT 
                COUNT(*) as total,
                AVG(profit_factor) as avg_pf,
                MIN(profit_factor) as min_pf,
                MAX(profit_factor) as max_pf,
                COUNT(CASE WHEN profit_factor >= 2.0 THEN 1 END) as excellent,
                COUNT(CASE WHEN profit_factor >= 1.5 AND profit_factor < 2.0 THEN 1 END) as good,
                COUNT(CASE WHEN profit_factor >= 1.0 AND profit_factor < 1.5 THEN 1 END) as profitable,
                COUNT(CASE WHEN profit_factor < 1.0 THEN 1 END) as losing
            FROM best_genomes
        """)
        
        row = cursor.fetchone()
        total, avg_pf, min_pf, max_pf, excellent, good, profitable, losing = row
        
        print(f"  æ€»è®°å½•: {total}")
        print(f"  å¹³å‡PF: {avg_pf:.2f}")
        print(f"  PFèŒƒå›´: [{min_pf:.2f}, {max_pf:.2f}]")
        print(f"\n  åˆ†çº§ç»Ÿè®¡:")
        print(f"  - ä¼˜ç§€ (PFâ‰¥2.0): {excellent} ({excellent/total*100:.1f}%)")
        print(f"  - è‰¯å¥½ (1.5â‰¤PF<2.0): {good} ({good/total*100:.1f}%)")
        print(f"  - ç›ˆåˆ© (1.0â‰¤PF<1.5): {profitable} ({profitable/total*100:.1f}%)")
        print(f"  - äºæŸ (PF<1.0): {losing} ({losing/total*100:.1f}%)")
        
        # 5.2 directional_biasåˆ†å¸ƒï¼ˆå¤šæ ·æ€§æŒ‡æ ‡ï¼‰
        print(f"\nã€æ–¹å‘åå¥½åˆ†å¸ƒï¼ˆå¤šæ ·æ€§æŒ‡æ ‡ï¼‰ã€‘")
        cursor = conn.execute("""
            SELECT genome FROM best_genomes
        """)
        
        import json
        biases = []
        for row in cursor:
            genome_dict = json.loads(row[0])
            bias = genome_dict.get('directional_bias', 0.5)
            biases.append(bias)
        
        biases = np.array(biases)
        
        bulls = np.sum(biases > 0.6)  # åå¤š
        bears = np.sum(biases < 0.4)  # åç©º
        neutral = np.sum((biases >= 0.4) & (biases <= 0.6))  # ä¸­æ€§
        
        print(f"  å¹³å‡æ–¹å‘åå¥½: {np.mean(biases):.3f}")
        print(f"  æ ‡å‡†å·®: {np.std(biases):.3f}")
        print(f"\n  æ–¹å‘åˆ†å¸ƒ:")
        print(f"  - åå¤š (>0.6): {bulls} ({bulls/len(biases)*100:.1f}%)")
        print(f"  - ä¸­æ€§ (0.4-0.6): {neutral} ({neutral/len(biases)*100:.1f}%)")
        print(f"  - åç©º (<0.4): {bears} ({bears/len(biases)*100:.1f}%)")
        
        # è®¡ç®—å¤šæ ·æ€§ç†µ
        diversity_entropy = -np.sum([
            (bulls/len(biases)) * np.log(bulls/len(biases) + 1e-10),
            (neutral/len(biases)) * np.log(neutral/len(biases) + 1e-10),
            (bears/len(biases)) * np.log(bears/len(biases) + 1e-10)
        ])
        max_entropy = np.log(3)
        diversity_score = diversity_entropy / max_entropy
        
        print(f"\n  å¤šæ ·æ€§ç†µ: {diversity_entropy:.3f} / {max_entropy:.3f}")
        print(f"  å¤šæ ·æ€§åˆ†æ•°: {diversity_score*100:.1f}%")
        
        if diversity_score > 0.8:
            print(f"  âœ… å¤šæ ·æ€§ä¼˜ç§€ï¼ˆ>80%ï¼‰")
        elif diversity_score > 0.6:
            print(f"  âš ï¸  å¤šæ ·æ€§ä¸­ç­‰ï¼ˆ60-80%ï¼‰")
        else:
            print(f"  âŒ å¤šæ ·æ€§ä¸è¶³ï¼ˆ<60%ï¼‰- Immigrationå¯èƒ½éœ€è¦å¢å¼º")
        
        # 5.3 Top 10åŸºå› 
        print(f"\nã€Top 10 åŸºå› ï¼ˆæŒ‰PFæ’åºï¼‰ã€‘")
        cursor = conn.execute("""
            SELECT roi, profit_factor, trade_count, genome
            FROM best_genomes
            ORDER BY profit_factor DESC
            LIMIT 10
        """)
        
        print(f"\n  {'ROI':>10} {'PF':>8} {'äº¤æ˜“æ•°':>8} {'æ–¹å‘åå¥½':>10}")
        print(f"  {'-'*10} {'-'*8} {'-'*8} {'-'*10}")
        
        for row in cursor:
            roi, pf, trade_count, genome_str = row
            genome_dict = json.loads(genome_str)
            bias = genome_dict.get('directional_bias', 0.5)
            
            print(f"  {roi*100:>9.2f}% {pf:>8.2f} {trade_count:>8} {bias:>10.3f}")
        
        conn.close()
    
    print("\n" + "="*80)
    print("âœ… Stage 1.1 å®Œæ•´è®­ç»ƒå®Œæˆï¼")
    print("="*80 + "\n")
    
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - å¸‚åœºæ•°æ®: data/stage1_1_training_market.csv")
    print(f"   - ç»éªŒåº“: {config.experience_db_path}")
    print(f"   - æ—¥å¿—: {result.log_file}")
    print(f"   - æŠ¥å‘Š: {result.report_file}")
    print("")
    
    return result


if __name__ == '__main__':
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    try:
        result = run_full_training()
        print("\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

